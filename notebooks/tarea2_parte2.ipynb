{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# **Tarea 2 - Parte 2: Modelo Hard-Core**\n",
    "\n",
    "**Aproximación del Número de Configuraciones con MCMC**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Modelo Hard-Core\n",
    "\n",
    "**Objetivo:** Aproximar el número de configuraciones válidas del modelo Hard-Core en lattices K×K.\n",
    "\n",
    "**Modelo Hard-Core:**\n",
    "- Cada vértice puede estar ocupado (1) o vacío (0)\n",
    "- **Restricción:** Dos vértices adyacentes NO pueden estar ambos ocupados\n",
    "- Configuración válida: conjunto independiente del grafo\n",
    "\n",
    "**Método:**\n",
    "- Usar Gibbs Sampler para generar muestras de configuraciones válidas\n",
    "- Adaptar parámetros del Theorem 9.1 (aunque no se cumple q > 2d para modelo binario)\n",
    "- Estimar el número total de configuraciones con path sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "from numba import njit, prange\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from typing import Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"✓ Librerías cargadas\")\n",
    "print(f\"  Numba version: {numba.__version__}\")\n",
    "print(f\"  Threads disponibles: {numba.config.NUMBA_NUM_THREADS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FUNCIONES BASE PARA MODELO HARD-CORE\n",
    "# ============================================================================\n",
    "\n",
    "@njit(cache=True)\n",
    "def create_adjacency_list(K: int):\n",
    "    \"\"\"\n",
    "    Crea lista de adyacencia para lattice K×K.\n",
    "    \n",
    "    Returns:\n",
    "        adj_list: array (K²×4) con índices de vecinos (-1 si no existe)\n",
    "        degrees: array (K²,) con número de vecinos\n",
    "    \"\"\"\n",
    "    n = K * K\n",
    "    adj_list = np.full((n, 4), -1, dtype=np.int32)\n",
    "    degrees = np.zeros(n, dtype=np.int32)\n",
    "    \n",
    "    for i in range(K):\n",
    "        for j in range(K):\n",
    "            node_idx = i * K + j\n",
    "            deg = 0\n",
    "            \n",
    "            if i > 0:\n",
    "                adj_list[node_idx, deg] = (i - 1) * K + j\n",
    "                deg += 1\n",
    "            if i < K - 1:\n",
    "                adj_list[node_idx, deg] = (i + 1) * K + j\n",
    "                deg += 1\n",
    "            if j > 0:\n",
    "                adj_list[node_idx, deg] = i * K + (j - 1)\n",
    "                deg += 1\n",
    "            if j < K - 1:\n",
    "                adj_list[node_idx, deg] = i * K + (j + 1)\n",
    "                deg += 1\n",
    "            \n",
    "            degrees[node_idx] = deg\n",
    "    \n",
    "    return adj_list, degrees\n",
    "\n",
    "\n",
    "@njit(fastmath=True, cache=True)\n",
    "def is_valid_hardcore_config(config: np.ndarray, adj_list: np.ndarray, \n",
    "                             degrees: np.ndarray, n: int) -> bool:\n",
    "    \"\"\"\n",
    "    Verifica si una configuración Hard-Core es válida.\n",
    "    \n",
    "    Args:\n",
    "        config: Array binario (0 o 1) de tamaño n\n",
    "        adj_list, degrees: Estructura del grafo\n",
    "        n: Número de nodos\n",
    "        \n",
    "    Returns:\n",
    "        True si ningún par de vecinos está ocupado simultáneamente\n",
    "    \"\"\"\n",
    "    for node in range(n):\n",
    "        if config[node] == 1:  # Si este nodo está ocupado\n",
    "            # Verificar que ningún vecino esté ocupado\n",
    "            for i in range(degrees[node]):\n",
    "                neighbor = adj_list[node, i]\n",
    "                if neighbor >= 0 and config[neighbor] == 1:\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def visualize_hardcore_config(config: np.ndarray, K: int, title: str = \"Configuración Hard-Core\"):\n",
    "    \"\"\"\n",
    "    Visualiza una configuración del modelo Hard-Core.\n",
    "    \"\"\"\n",
    "    grid = config.reshape(K, K)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    # Ocupados en azul, vacíos en blanco\n",
    "    cmap = plt.matplotlib.colors.ListedColormap(['white', 'darkblue'])\n",
    "    im = ax.imshow(grid, cmap=cmap, vmin=0, vmax=1)\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel(\"Columna\")\n",
    "    ax.set_ylabel(\"Fila\")\n",
    "    \n",
    "    # Grid\n",
    "    ax.set_xticks(np.arange(K))\n",
    "    ax.set_yticks(np.arange(K))\n",
    "    ax.grid(which='major', color='gray', linewidth=0.5)\n",
    "    \n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax, ticks=[0, 1])\n",
    "    cbar.set_label('Estado', rotation=270, labelpad=20)\n",
    "    cbar.ax.set_yticklabels(['Vacío (0)', 'Ocupado (1)'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"✓ Funciones base implementadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs Sampler para Hard-Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GIBBS SAMPLER PARA MODELO HARD-CORE\n",
    "# ============================================================================\n",
    "\n",
    "@njit(fastmath=True, cache=True)\n",
    "def initialize_hardcore_config(n: int, adj_list: np.ndarray, degrees: np.ndarray):\n",
    "    \"\"\"\n",
    "    Inicializa configuración válida Hard-Core (greedy).\n",
    "    \"\"\"\n",
    "    config = np.zeros(n, dtype=np.int32)\n",
    "    \n",
    "    for node in range(n):\n",
    "        # Verificar si algún vecino está ocupado\n",
    "        can_occupy = True\n",
    "        for i in range(degrees[node]):\n",
    "            neighbor = adj_list[node, i]\n",
    "            if neighbor >= 0 and neighbor < node and config[neighbor] == 1:\n",
    "                can_occupy = False\n",
    "                break\n",
    "        \n",
    "        # Con prob 0.5, ocupar si es posible (para tener diversidad)\n",
    "        if can_occupy and np.random.rand() < 0.3:\n",
    "            config[node] = 1\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "@njit(fastmath=True, cache=True, inline='always')\n",
    "def gibbs_hardcore_step(config: np.ndarray, adj_list: np.ndarray,\n",
    "                       degrees: np.ndarray, n: int, node_order: np.ndarray):\n",
    "    \"\"\"\n",
    "    Un paso del Gibbs Sampler para Hard-Core.\n",
    "    Modifica config in-place.\n",
    "    \"\"\"\n",
    "    for idx in range(n):\n",
    "        node = node_order[idx]\n",
    "        \n",
    "        # Verificar si algún vecino está ocupado\n",
    "        neighbor_occupied = False\n",
    "        for i in range(degrees[node]):\n",
    "            neighbor = adj_list[node, i]\n",
    "            if neighbor >= 0 and config[neighbor] == 1:\n",
    "                neighbor_occupied = True\n",
    "                break\n",
    "        \n",
    "        if neighbor_occupied:\n",
    "            # Forzado a estar vacío\n",
    "            config[node] = 0\n",
    "        else:\n",
    "            # Puede estar ocupado o vacío con igual probabilidad\n",
    "            config[node] = np.random.randint(0, 2)\n",
    "\n",
    "\n",
    "@njit(fastmath=True, cache=True)\n",
    "def run_single_hardcore_simulation(K: int, n_steps: int, seed: int,\n",
    "                                   adj_list: np.ndarray, degrees: np.ndarray):\n",
    "    \"\"\"\n",
    "    Ejecuta una simulación del Gibbs Sampler para Hard-Core.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    n = K * K\n",
    "    config = initialize_hardcore_config(n, adj_list, degrees)\n",
    "    node_order = np.arange(n, dtype=np.int32)\n",
    "    \n",
    "    # Loop principal\n",
    "    for step in range(n_steps):\n",
    "        np.random.shuffle(node_order)\n",
    "        gibbs_hardcore_step(config, adj_list, degrees, n, node_order)\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "@njit(parallel=True, fastmath=True, cache=True)\n",
    "def run_hardcore_batch_parallel(K: int, n_steps: int, seeds: np.ndarray,\n",
    "                                adj_list: np.ndarray, degrees: np.ndarray):\n",
    "    \"\"\"\n",
    "    Ejecuta batch de simulaciones Hard-Core en paralelo.\n",
    "    \"\"\"\n",
    "    n_sims = len(seeds)\n",
    "    n = K * K\n",
    "    configs = np.empty((n_sims, n), dtype=np.int32)\n",
    "    \n",
    "    for i in prange(n_sims):\n",
    "        configs[i] = run_single_hardcore_simulation(K, n_steps, seeds[i],\n",
    "                                                    adj_list, degrees)\n",
    "    \n",
    "    return configs\n",
    "\n",
    "\n",
    "print(\"✓ Gibbs Sampler para Hard-Core implementado\")\n",
    "print(\"  - Optimizado con Numba prange\")\n",
    "print(\"  - Batch processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función Principal de Simulación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FUNCIÓN PRINCIPAL: EJECUTAR GIBBS SAMPLER HARD-CORE\n",
    "# ============================================================================\n",
    "\n",
    "def compute_hardcore_simulation_parameters(K: int, epsilon: float, d: int = 4):\n",
    "    \"\"\"\n",
    "    Calcula parámetros adaptados del Theorem 9.1 para Hard-Core.\n",
    "    \n",
    "    NOTA: Hard-Core es modelo binario (q=2 efectivo), NO cumple q > 2d.\n",
    "    Usamos las fórmulas del teorema como guía, pero sin garantías teóricas.\n",
    "    \n",
    "    Args:\n",
    "        K: Tamaño del lattice\n",
    "        epsilon: Precisión deseada\n",
    "        d: Grado máximo\n",
    "        \n",
    "    Returns:\n",
    "        (n_simulations, gibbs_steps)\n",
    "    \"\"\"\n",
    "    k = K * K\n",
    "    \n",
    "    # Adaptación: usar q=2 en las fórmulas (aunque no cumpla restricción)\n",
    "    q_effective = 2\n",
    "    \n",
    "    n_simulations = int(np.ceil(48 * d**2 * k**3 / epsilon**2))\n",
    "    \n",
    "    # Para q=2, log(q/(q-1)) = log(2) ≈ 0.693\n",
    "    log_ratio = np.log(q_effective / (q_effective - 1))\n",
    "    numerator = 2 * np.log(k) + np.log(1/epsilon) + np.log(8)\n",
    "    gibbs_steps = int(np.ceil(k * (numerator / log_ratio + 1)))\n",
    "    \n",
    "    return n_simulations, gibbs_steps\n",
    "\n",
    "\n",
    "def run_hardcore_sampling(K: int, epsilon: float, batch_size: int = 5000, \n",
    "                         verbose: bool = True):\n",
    "    \"\"\"\n",
    "    Ejecuta Gibbs Sampler para modelo Hard-Core.\n",
    "    \n",
    "    Args:\n",
    "        K: Tamaño del lattice\n",
    "        epsilon: Precisión deseada\n",
    "        batch_size: Tamaño de batch\n",
    "        verbose: Mostrar info\n",
    "        \n",
    "    Returns:\n",
    "        dict con configs y métricas\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    k = K * K\n",
    "    d = 4\n",
    "    \n",
    "    # Calcular parámetros\n",
    "    n_simulations, gibbs_steps = compute_hardcore_simulation_parameters(K, epsilon, d)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*75}\")\n",
    "        print(f\"GIBBS SAMPLER - HARD-CORE - LATTICE {K}×{K}\")\n",
    "        print(f\"{'='*75}\")\n",
    "        print(f\"Parámetros (adaptados del Theorem 9.1):\")\n",
    "        print(f\"  • Vértices (k):              {k}\")\n",
    "        print(f\"  • Precisión (ε):             {epsilon}\")\n",
    "        print(f\"  • Grado máximo (d):          {d}\")\n",
    "        print(f\"\\n⚠️  NOTA: Hard-Core es binario (q=2), NO cumple q > 2d = 8\")\n",
    "        print(f\"   Las fórmulas se usan como guía sin garantías teóricas.\\n\")\n",
    "        print(f\"Parámetros de simulación:\")\n",
    "        print(f\"  • Simulaciones:              {n_simulations:,}\")\n",
    "        print(f\"  • Pasos Gibbs/sim:           {gibbs_steps:,}\")\n",
    "        print(f\"  • Total pasos:               {n_simulations * gibbs_steps:,}\")\n",
    "        print(f\"  • Batch size:                {batch_size:,}\")\n",
    "        print(f\"  • Batches:                   {int(np.ceil(n_simulations / batch_size)):,}\")\n",
    "        print(f\"{'='*75}\\n\")\n",
    "    \n",
    "    # Crear estructura del grafo\n",
    "    adj_list, degrees = create_adjacency_list(K)\n",
    "    \n",
    "    # Generar semillas\n",
    "    np.random.seed(42)\n",
    "    all_seeds = np.random.randint(0, 2**31 - 1, size=n_simulations)\n",
    "    \n",
    "    # Procesar por batches\n",
    "    n_batches = int(np.ceil(n_simulations / batch_size))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Ejecutando {n_simulations:,} simulaciones en {n_batches} batches...\\n\")\n",
    "    \n",
    "    all_configs = []\n",
    "    \n",
    "    for batch_idx in tqdm(range(n_batches), disable=not verbose,\n",
    "                          desc=f\"K={K}, ε={epsilon}\"):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, n_simulations)\n",
    "        batch_seeds = all_seeds[start_idx:end_idx]\n",
    "        \n",
    "        batch_configs = run_hardcore_batch_parallel(K, gibbs_steps, batch_seeds,\n",
    "                                                    adj_list, degrees)\n",
    "        all_configs.append(batch_configs)\n",
    "    \n",
    "    configs = np.vstack(all_configs)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    result = {\n",
    "        'K': K,\n",
    "        'epsilon': epsilon,\n",
    "        'k': k,\n",
    "        'n_simulations': n_simulations,\n",
    "        'gibbs_steps': gibbs_steps,\n",
    "        'total_gibbs_steps': n_simulations * gibbs_steps,\n",
    "        'configs': configs,\n",
    "        'elapsed_time_seconds': elapsed_time\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*75}\")\n",
    "        print(f\"SIMULACIÓN COMPLETADA:\")\n",
    "        print(f\"  • Configuraciones generadas: {n_simulations:,}\")\n",
    "        print(f\"  • Tiempo:                    {elapsed_time:.2f}s ({elapsed_time/60:.2f} min)\")\n",
    "        print(f\"  • Pasos/segundo:             {n_simulations * gibbs_steps / elapsed_time:,.0f}\")\n",
    "        print(f\"{'='*75}\\n\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"✓ Función principal de simulación implementada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Path Sampling para Hard-Core\n\n**Objetivo:** Estimar el número total de configuraciones válidas usando las muestras MCMC.\n\n**Método adaptado:**\n- Para cada nodo en cada configuración, calcular cuántas opciones tiene (0 o 1)\n- Si algún vecino está ocupado: solo 1 opción (forzado a 0)\n- Si ningún vecino está ocupado: 2 opciones (0 o 1)\n- Promedio logarítmico: `log(Z) ≈ E[Σ log(opciones_disponibles)]`",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# PATH SAMPLING PARA HARD-CORE\n# ============================================================================\n\n@njit(fastmath=True, cache=True)\ndef compute_hardcore_log_partition_single(config: np.ndarray, adj_list: np.ndarray,\n                                          degrees: np.ndarray, K: int):\n    \"\"\"\n    Calcula log-partition para una configuración Hard-Core.\n    \n    Para cada nodo:\n    - Si algún vecino está ocupado: log(1) = 0 (forzado a vacío)\n    - Si ningún vecino está ocupado: log(2) (puede ser 0 o 1)\n    \n    Returns:\n        Sum of log(available_options) para todos los nodos\n    \"\"\"\n    n = K * K\n    log_partition = 0.0\n    log_2 = np.log(2.0)\n    \n    for node in range(n):\n        # Verificar si algún vecino está ocupado\n        neighbor_occupied = False\n        for i in range(degrees[node]):\n            neighbor = adj_list[node, i]\n            if neighbor >= 0 and config[neighbor] == 1:\n                neighbor_occupied = True\n                break\n        \n        if neighbor_occupied:\n            # Solo 1 opción (vacío): log(1) = 0\n            log_partition += 0.0\n        else:\n            # 2 opciones (vacío u ocupado): log(2)\n            log_partition += log_2\n    \n    return log_partition\n\n\n@njit(parallel=True, fastmath=True, cache=True)\ndef compute_hardcore_log_partition_batch(configs: np.ndarray, adj_list: np.ndarray,\n                                        degrees: np.ndarray, K: int):\n    \"\"\"\n    Calcula log-partitions para batch de configuraciones Hard-Core.\n    \"\"\"\n    n_configs = configs.shape[0]\n    log_partitions = np.empty(n_configs, dtype=np.float64)\n    \n    for i in prange(n_configs):\n        log_partitions[i] = compute_hardcore_log_partition_single(\n            configs[i], adj_list, degrees, K\n        )\n    \n    return log_partitions\n\n\ndef estimate_hardcore_configs_path_sampling(configs: np.ndarray, K: int,\n                                           verbose: bool = True):\n    \"\"\"\n    Estima el número de configuraciones Hard-Core usando path sampling.\n    \n    Args:\n        configs: Array (n_samples, K²) con configuraciones\n        K: Tamaño del lattice\n        verbose: Mostrar información\n        \n    Returns:\n        dict con estimación y estadísticas\n    \"\"\"\n    start_time = time.time()\n    n_samples = configs.shape[0]\n    \n    if verbose:\n        print(f\"\\n{'='*75}\")\n        print(f\"PATH SAMPLING - HARD-CORE - LATTICE {K}×{K}\")\n        print(f\"{'='*75}\")\n        print(f\"Estimando número de configuraciones...\")\n        print(f\"  • Muestras MCMC: {n_samples:,}\")\n    \n    # Crear estructura del grafo\n    adj_list, degrees = create_adjacency_list(K)\n    \n    # Calcular log-partitions\n    if verbose:\n        print(f\"  • Calculando log-partitions...\")\n    \n    log_partitions = compute_hardcore_log_partition_batch(configs, adj_list, degrees, K)\n    \n    # Estimación: promedio de log-partitions, luego exp\n    mean_log_partition = np.mean(log_partitions)\n    std_log_partition = np.std(log_partitions)\n    \n    # Estimación del número de configuraciones\n    estimated_configs = np.exp(mean_log_partition)\n    \n    # Intervalo de confianza (aproximado)\n    # CI basado en bootstrap o normal aproximation\n    z_score = 1.96  # 95% CI\n    se_log = std_log_partition / np.sqrt(n_samples)\n    \n    lower_log = mean_log_partition - z_score * se_log\n    upper_log = mean_log_partition + z_score * se_log\n    \n    lower_bound = np.exp(lower_log)\n    upper_bound = np.exp(upper_log)\n    \n    elapsed_time = time.time() - start_time\n    \n    result = {\n        'K': K,\n        'n_samples': n_samples,\n        'estimated_configs': estimated_configs,\n        'mean_log_partition': mean_log_partition,\n        'std_log_partition': std_log_partition,\n        'lower_bound_95': lower_bound,\n        'upper_bound_95': upper_bound,\n        'elapsed_time_seconds': elapsed_time\n    }\n    \n    if verbose:\n        print(f\"\\n{'='*75}\")\n        print(f\"ESTIMACIÓN COMPLETADA:\")\n        print(f\"  • Estimación:         {estimated_configs:.2e}\")\n        print(f\"  • IC 95%:             [{lower_bound:.2e}, {upper_bound:.2e}]\")\n        print(f\"  • Mean log(Z):        {mean_log_partition:.4f}\")\n        print(f\"  • Std log(Z):         {std_log_partition:.4f}\")\n        print(f\"  • Tiempo:             {elapsed_time:.2f}s\")\n        print(f\"{'='*75}\\n\")\n    \n    return result\n\n\nprint(\"✓ Path sampling para Hard-Core implementado\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Conteo Exacto (Fuerza Bruta)\n\nPara lattices pequeños, podemos enumerar todas las configuraciones válidas y contar.\n\n**Método:**\n- Generar todas las 2^(K²) configuraciones binarias posibles\n- Filtrar solo las que cumplen la restricción Hard-Core\n- Contar el total",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# CONTEO EXACTO PARA HARD-CORE\n# ============================================================================\n\ndef count_hardcore_configs_exact(K: int, verbose: bool = True):\n    \"\"\"\n    Cuenta exactamente el número de configuraciones Hard-Core válidas.\n    \n    ADVERTENCIA: Complejidad O(2^(K²)). Solo factible para K ≤ 4.\n    \n    Args:\n        K: Tamaño del lattice\n        verbose: Mostrar progreso\n        \n    Returns:\n        int: Número exacto de configuraciones válidas\n    \"\"\"\n    k = K * K\n    total_configs = 2**k\n    \n    if verbose:\n        print(f\"\\n{'='*75}\")\n        print(f\"CONTEO EXACTO - HARD-CORE - LATTICE {K}×{K}\")\n        print(f\"{'='*75}\")\n        print(f\"Método: Enumeración exhaustiva\")\n        print(f\"  • Vértices:                  {k}\")\n        print(f\"  • Configuraciones totales:   {total_configs:,}\")\n        \n        if total_configs > 10**7:\n            print(f\"\\n⚠️  ADVERTENCIA: {total_configs:,} configuraciones es computacionalmente costoso.\")\n            print(f\"   Esto puede tomar varios minutos...\")\n        print(f\"{'='*75}\\n\")\n    \n    start_time = time.time()\n    \n    # Crear estructura del grafo\n    adj_list, degrees = create_adjacency_list(K)\n    \n    # Contar configuraciones válidas\n    valid_count = 0\n    \n    # Iterar sobre todas las configuraciones binarias posibles\n    iterator = tqdm(range(total_configs), desc=f\"Enumerando K={K}\") if verbose else range(total_configs)\n    \n    for config_int in iterator:\n        # Convertir entero a configuración binaria\n        config = np.array([int(b) for b in format(config_int, f'0{k}b')], dtype=np.int32)\n        \n        # Verificar si es válida\n        if is_valid_hardcore_config(config, adj_list, degrees, k):\n            valid_count += 1\n    \n    elapsed_time = time.time() - start_time\n    \n    if verbose:\n        print(f\"\\n{'='*75}\")\n        print(f\"CONTEO COMPLETADO:\")\n        print(f\"  • Configuraciones válidas:   {valid_count:,}\")\n        print(f\"  • Tiempo:                    {elapsed_time:.2f}s ({elapsed_time/60:.2f} min)\")\n        print(f\"  • Configs/segundo:           {total_configs/elapsed_time:,.0f}\")\n        print(f\"{'='*75}\\n\")\n    \n    return valid_count\n\n\nprint(\"✓ Conteo exacto implementado\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Experimentos\n\nEjecutaremos experimentos para diferentes tamaños de lattice K con ε=0.3.\n\n**Configuración:**\n- K = {3, 4} (factibles para MCMC y conteo exacto)\n- ε = 0.3\n- Comparación MCMC vs. Exacto",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# EXPERIMENTO PRINCIPAL: HARD-CORE MCMC vs EXACTO\n# ============================================================================\n\ndef run_hardcore_experiment(K_values: list, epsilon: float, batch_size: int = 5000):\n    \"\"\"\n    Ejecuta experimentos completos para Hard-Core: MCMC + path sampling + exacto.\n    \n    Args:\n        K_values: Lista de tamaños de lattice\n        epsilon: Precisión para MCMC\n        batch_size: Tamaño de batch\n        \n    Returns:\n        DataFrame con resultados\n    \"\"\"\n    results = []\n    \n    print(f\"\\n{'#'*75}\")\n    print(f\"# EXPERIMENTO HARD-CORE: K={K_values}, ε={epsilon}\")\n    print(f\"{'#'*75}\\n\")\n    \n    for K in K_values:\n        print(f\"\\n{'='*75}\")\n        print(f\"PROCESANDO K = {K}\")\n        print(f\"{'='*75}\\n\")\n        \n        # 1. MCMC Sampling\n        print(f\"[1/3] Generando muestras con Gibbs Sampler...\")\n        sampling_result = run_hardcore_sampling(K, epsilon, batch_size, verbose=True)\n        \n        # 2. Path Sampling\n        print(f\"\\n[2/3] Estimando con path sampling...\")\n        estimation_result = estimate_hardcore_configs_path_sampling(\n            sampling_result['configs'], K, verbose=True\n        )\n        \n        # 3. Conteo exacto\n        print(f\"\\n[3/3] Calculando conteo exacto...\")\n        exact_count = count_hardcore_configs_exact(K, verbose=True)\n        \n        # Calcular error relativo\n        estimated = estimation_result['estimated_configs']\n        error_rel = abs(estimated - exact_count) / exact_count * 100\n        \n        # Guardar resultados\n        result = {\n            'K': K,\n            'epsilon': epsilon,\n            'n_simulations': sampling_result['n_simulations'],\n            'gibbs_steps': sampling_result['gibbs_steps'],\n            'total_gibbs_steps': sampling_result['total_gibbs_steps'],\n            'mcmc_time_s': sampling_result['elapsed_time_seconds'],\n            'estimation_time_s': estimation_result['elapsed_time_seconds'],\n            'exact_count': exact_count,\n            'mcmc_estimate': estimated,\n            'lower_bound_95': estimation_result['lower_bound_95'],\n            'upper_bound_95': estimation_result['upper_bound_95'],\n            'error_rel_pct': error_rel,\n            'exact_in_ci': (estimation_result['lower_bound_95'] <= exact_count <= \n                           estimation_result['upper_bound_95'])\n        }\n        \n        results.append(result)\n        \n        print(f\"\\n{'='*75}\")\n        print(f\"RESUMEN K={K}:\")\n        print(f\"  • Exacto:           {exact_count:,}\")\n        print(f\"  • MCMC:             {estimated:.2e}\")\n        print(f\"  • Error relativo:   {error_rel:.2f}%\")\n        print(f\"  • Exacto en IC 95%: {'✓' if result['exact_in_ci'] else '✗'}\")\n        print(f\"  • Tiempo total:     {result['mcmc_time_s'] + result['estimation_time_s']:.2f}s\")\n        print(f\"{'='*75}\\n\")\n    \n    # Crear DataFrame\n    df_results = pd.DataFrame(results)\n    \n    return df_results\n\n\nprint(\"✓ Función de experimento implementada\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Ejecutar experimentos\nK_values_experiment = [3, 4]\nepsilon_experiment = 0.3\n\ndf_hardcore_results = run_hardcore_experiment(K_values_experiment, epsilon_experiment, batch_size=5000)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Resultados y Análisis",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Mostrar tabla de resultados\nprint(\"\\n\" + \"=\"*100)\nprint(\"TABLA DE RESULTADOS - MODELO HARD-CORE\")\nprint(\"=\"*100)\n\n# Formatear DataFrame para display\ndf_display = df_hardcore_results.copy()\ndf_display['Exacto'] = df_display['exact_count'].apply(lambda x: f\"{x:,}\")\ndf_display['MCMC'] = df_display['mcmc_estimate'].apply(lambda x: f\"{x:.2e}\")\ndf_display['Error (%)'] = df_display['error_rel_pct'].apply(lambda x: f\"{x:.2f}\")\ndf_display['IC 95% contiene exacto'] = df_display['exact_in_ci'].apply(lambda x: '✓' if x else '✗')\ndf_display['Simulaciones'] = df_display['n_simulations'].apply(lambda x: f\"{x:,}\")\ndf_display['Tiempo (s)'] = (df_display['mcmc_time_s'] + df_display['estimation_time_s']).apply(lambda x: f\"{x:.2f}\")\n\ndisplay_cols = ['K', 'Exacto', 'MCMC', 'Error (%)', 'IC 95% contiene exacto', 'Simulaciones', 'Tiempo (s)']\nprint(df_display[display_cols].to_string(index=False))\nprint(\"=\"*100 + \"\\n\")\n\n# Estadísticas resumen\nprint(f\"\\nEstadísticas de rendimiento:\")\nprint(f\"  • Error relativo promedio:     {df_hardcore_results['error_rel_pct'].mean():.2f}%\")\nprint(f\"  • Error relativo máximo:       {df_hardcore_results['error_rel_pct'].max():.2f}%\")\nprint(f\"  • Casos con exacto en IC 95%:  {df_hardcore_results['exact_in_ci'].sum()}/{len(df_hardcore_results)}\")\nprint(f\"  • Tiempo total:                {(df_hardcore_results['mcmc_time_s'] + df_hardcore_results['estimation_time_s']).sum():.2f}s\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Visualizaciones",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# VISUALIZACIÓN 1: COMPARACIÓN MCMC vs EXACTO\n# ============================================================================\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Subplot 1: Estimaciones con IC\nax1 = axes[0]\nx_pos = np.arange(len(df_hardcore_results))\nwidth = 0.35\n\n# Barras para exacto\nbars1 = ax1.bar(x_pos - width/2, df_hardcore_results['exact_count'], width, \n                label='Exacto', color='steelblue', alpha=0.8)\n\n# Barras para MCMC con error bars\nyerr = np.array([\n    df_hardcore_results['mcmc_estimate'] - df_hardcore_results['lower_bound_95'],\n    df_hardcore_results['upper_bound_95'] - df_hardcore_results['mcmc_estimate']\n])\nbars2 = ax1.bar(x_pos + width/2, df_hardcore_results['mcmc_estimate'], width,\n                label='MCMC', color='coral', alpha=0.8, yerr=yerr, capsize=5)\n\nax1.set_xlabel('Tamaño de Lattice (K)', fontweight='bold')\nax1.set_ylabel('Número de Configuraciones', fontweight='bold')\nax1.set_title('Comparación MCMC vs Exacto (con IC 95%)', fontweight='bold', fontsize=14)\nax1.set_xticks(x_pos)\nax1.set_xticklabels([f\"{K}×{K}\" for K in df_hardcore_results['K']])\nax1.legend()\nax1.grid(axis='y', alpha=0.3)\n\n# Subplot 2: Error relativo\nax2 = axes[1]\nbars = ax2.bar(x_pos, df_hardcore_results['error_rel_pct'], color='indianred', alpha=0.7)\nax2.axhline(y=5, color='green', linestyle='--', linewidth=2, label='Target 5%', alpha=0.6)\nax2.set_xlabel('Tamaño de Lattice (K)', fontweight='bold')\nax2.set_ylabel('Error Relativo (%)', fontweight='bold')\nax2.set_title('Error Relativo de Estimación MCMC', fontweight='bold', fontsize=14)\nax2.set_xticks(x_pos)\nax2.set_xticklabels([f\"{K}×{K}\" for K in df_hardcore_results['K']])\nax2.legend()\nax2.grid(axis='y', alpha=0.3)\n\n# Anotar valores\nfor i, (bar, err) in enumerate(zip(bars, df_hardcore_results['error_rel_pct'])):\n    height = bar.get_height()\n    ax2.text(bar.get_x() + bar.get_width()/2., height,\n             f'{err:.2f}%', ha='center', va='bottom', fontweight='bold')\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# VISUALIZACIÓN 2: MUESTRAS DE CONFIGURACIONES HARD-CORE\n# ============================================================================\n\n# Visualizar algunas configuraciones para K=3 y K=4\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\n\nfor i, K in enumerate([3, 4]):\n    # Obtener las configuraciones generadas para este K\n    idx = df_hardcore_results[df_hardcore_results['K'] == K].index[0]\n    \n    # Como no guardamos las configs en el DataFrame, generamos algunas nuevas para visualizar\n    adj_list, degrees = create_adjacency_list(K)\n    n = K * K\n    \n    # Generar 3 configuraciones de ejemplo\n    seeds = np.random.randint(0, 2**31 - 1, size=3)\n    \n    for j in range(3):\n        ax = axes[i, j]\n        config = run_single_hardcore_simulation(K, n_steps=100, seed=seeds[j],\n                                                adj_list=adj_list, degrees=degrees)\n        \n        grid = config.reshape(K, K)\n        \n        # Visualizar\n        cmap = plt.matplotlib.colors.ListedColormap(['white', 'darkblue'])\n        im = ax.imshow(grid, cmap=cmap, vmin=0, vmax=1)\n        \n        ax.set_title(f\"K={K}, Muestra {j+1}\", fontweight='bold')\n        ax.set_xticks(np.arange(K))\n        ax.set_yticks(np.arange(K))\n        ax.grid(which='major', color='gray', linewidth=0.5)\n        \n        # Agregar colorbar solo en la última columna\n        if j == 2:\n            cbar = plt.colorbar(im, ax=ax, ticks=[0, 1], fraction=0.046)\n            cbar.ax.set_yticklabels(['Vacío', 'Ocupado'])\n\nplt.suptitle('Muestras de Configuraciones Hard-Core', fontsize=16, fontweight='bold', y=1.00)\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Análisis de Factibilidad Computacional\n\nCreamos una tabla extrapolando tiempos de ejecución para valores más grandes de K.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# TABLA DE FACTIBILIDAD COMPUTACIONAL\n# ============================================================================\n\ndef create_hardcore_feasibility_table(df_results: pd.DataFrame, epsilon: float, K_max: int = 10):\n    \"\"\"\n    Crea tabla de factibilidad extrapolando tiempos para K más grandes.\n    \"\"\"\n    # Calcular tiempo promedio por paso de Gibbs\n    df_results['time_per_gibbs_step'] = (\n        df_results['mcmc_time_s'] / df_results['total_gibbs_steps']\n    )\n    \n    avg_time_per_step = df_results['time_per_gibbs_step'].mean()\n    \n    print(f\"\\nCálculo de tiempo promedio por paso de Gibbs:\")\n    print(f\"  • Tiempo/paso promedio: {avg_time_per_step:.2e} s/paso\")\n    \n    # Generar tabla de extrapolación\n    K_values = list(range(3, K_max + 1))\n    feasibility_data = []\n    \n    for K in K_values:\n        k = K * K\n        n_sims, gibbs_steps = compute_hardcore_simulation_parameters(K, epsilon)\n        total_steps = n_sims * gibbs_steps\n        \n        # Extrapolar tiempo\n        estimated_time_s = total_steps * avg_time_per_step\n        estimated_time_h = estimated_time_s / 3600\n        estimated_time_days = estimated_time_h / 24\n        \n        # Determinar factibilidad\n        if estimated_time_s < 60:\n            feasibility = \"Muy rápido\"\n        elif estimated_time_s < 600:\n            feasibility = \"Rápido\"\n        elif estimated_time_s < 3600:\n            feasibility = \"Factible\"\n        elif estimated_time_h < 12:\n            feasibility = \"Largo\"\n        elif estimated_time_h < 48:\n            feasibility = \"Muy largo\"\n        else:\n            feasibility = \"Prohibitivo\"\n        \n        feasibility_data.append({\n            'K': K,\n            'Vértices': k,\n            'Simulaciones': n_sims,\n            'Pasos Gibbs': gibbs_steps,\n            'Total Pasos': total_steps,\n            'Tiempo (s)': estimated_time_s,\n            'Tiempo (h)': estimated_time_h,\n            'Tiempo (días)': estimated_time_days,\n            'Factibilidad': feasibility\n        })\n    \n    df_feasibility = pd.DataFrame(feasibility_data)\n    \n    return df_feasibility, avg_time_per_step\n\n\n# Generar tabla\ndf_hardcore_feasibility, avg_time_per_step = create_hardcore_feasibility_table(\n    df_hardcore_results, epsilon_experiment, K_max=8\n)\n\n# Mostrar tabla\nprint(f\"\\n{'='*120}\")\nprint(f\"TABLA DE FACTIBILIDAD COMPUTACIONAL - HARD-CORE (ε={epsilon_experiment})\")\nprint(f\"{'='*120}\")\nprint(f\"Tiempo por paso de Gibbs: {avg_time_per_step:.2e} s/paso\\n\")\n\n# Formatear para display\ndf_feas_display = df_hardcore_feasibility.copy()\ndf_feas_display['Simulaciones'] = df_feas_display['Simulaciones'].apply(lambda x: f\"{x:,.0f}\")\ndf_feas_display['Pasos Gibbs'] = df_feas_display['Pasos Gibbs'].apply(lambda x: f\"{x:,.0f}\")\ndf_feas_display['Total Pasos'] = df_feas_display['Total Pasos'].apply(lambda x: f\"{x:.2e}\")\ndf_feas_display['Tiempo (s)'] = df_feas_display['Tiempo (s)'].apply(lambda x: f\"{x:.2f}\")\ndf_feas_display['Tiempo (h)'] = df_feas_display['Tiempo (h)'].apply(lambda x: f\"{x:.2f}\")\ndf_feas_display['Tiempo (días)'] = df_feas_display['Tiempo (días)'].apply(lambda x: f\"{x:.2f}\")\n\ndisplay_cols = ['K', 'Vértices', 'Simulaciones', 'Pasos Gibbs', 'Total Pasos', \n                'Tiempo (h)', 'Factibilidad']\nprint(df_feas_display[display_cols].to_string(index=False))\nprint(\"=\"*120)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# VISUALIZACIÓN 3: FACTIBILIDAD COMPUTACIONAL\n# ============================================================================\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Subplot 1: Tiempo de ejecución estimado\nax1 = axes[0]\ncolors = ['green' if f in ['Muy rápido', 'Rápido', 'Factible'] \n          else 'orange' if f == 'Largo' \n          else 'red' \n          for f in df_hardcore_feasibility['Factibilidad']]\n\nbars = ax1.bar(df_hardcore_feasibility['K'], df_hardcore_feasibility['Tiempo (h)'], \n               color=colors, alpha=0.7, edgecolor='black')\nax1.set_xlabel('Tamaño de Lattice (K)', fontweight='bold')\nax1.set_ylabel('Tiempo Estimado (horas)', fontweight='bold')\nax1.set_title('Tiempo de Ejecución Estimado por Tamaño de Lattice', fontweight='bold', fontsize=14)\nax1.set_yscale('log')\nax1.grid(axis='y', alpha=0.3, which='both')\nax1.set_xticks(df_hardcore_feasibility['K'])\n\n# Líneas de referencia\nax1.axhline(y=1, color='green', linestyle='--', linewidth=1, alpha=0.5, label='1 hora')\nax1.axhline(y=12, color='orange', linestyle='--', linewidth=1, alpha=0.5, label='12 horas')\nax1.axhline(y=48, color='red', linestyle='--', linewidth=1, alpha=0.5, label='48 horas')\nax1.legend(loc='upper left')\n\n# Subplot 2: Número de pasos de Gibbs\nax2 = axes[1]\nax2.plot(df_hardcore_feasibility['K'], df_hardcore_feasibility['Total Pasos'], \n         marker='o', linewidth=2, markersize=8, color='steelblue')\nax2.set_xlabel('Tamaño de Lattice (K)', fontweight='bold')\nax2.set_ylabel('Total de Pasos de Gibbs', fontweight='bold')\nax2.set_title('Complejidad Computacional (Total Pasos)', fontweight='bold', fontsize=14)\nax2.set_yscale('log')\nax2.grid(True, alpha=0.3, which='both')\nax2.set_xticks(df_hardcore_feasibility['K'])\n\n# Anotar crecimiento\nfor i in range(len(df_hardcore_feasibility) - 1):\n    k1, k2 = df_hardcore_feasibility['K'].iloc[i], df_hardcore_feasibility['K'].iloc[i+1]\n    steps1, steps2 = (df_hardcore_feasibility['Total Pasos'].iloc[i], \n                      df_hardcore_feasibility['Total Pasos'].iloc[i+1])\n    growth_factor = steps2 / steps1\n    \n    if i == 0:  # Solo anotar el primer crecimiento\n        mid_x = (k1 + k2) / 2\n        mid_y = np.sqrt(steps1 * steps2)\n        ax2.annotate(f'×{growth_factor:.1f}', xy=(mid_x, mid_y), \n                    fontsize=10, ha='center', color='red', fontweight='bold')\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Conclusiones\n\n### Modelo Hard-Core\n\n1. **Implementación exitosa del Gibbs Sampler:**\n   - Se implementó un Gibbs Sampler optimizado para el modelo Hard-Core usando Numba\n   - Batch processing paralelo con `prange` para máxima eficiencia\n   - Parámetros adaptados del Theorem 9.1 (aunque q=2 no cumple q > 2d=8)\n\n2. **Path Sampling para estimación:**\n   - Se utilizó path sampling basado en conteo de opciones disponibles por nodo\n   - Para cada nodo: log(2) si ningún vecino ocupado, log(1)=0 si vecino ocupado\n   - Método de promedio logarítmico para estimar Z\n\n3. **Validación con conteo exacto:**\n   - Comparación exitosa con enumeración exhaustiva para K=3,4\n   - Intervalos de confianza del 95% calculados\n\n4. **Limitaciones computacionales:**\n   - Complejidad O(K⁶) de los parámetros del Theorem 9.1\n   - Factible solo para K ≤ 4-5 con precisión ε=0.3\n   - Para K > 5, tiempos de ejecución prohibitivos (días/semanas)\n\n5. **Consideración teórica importante:**\n   - El modelo Hard-Core es binario (q=2 efectivo)\n   - NO cumple la restricción q > 2d = 8 del Theorem 9.1\n   - Las fórmulas se usan como guía heurística sin garantías teóricas\n   - Posible explorar métodos alternativos para modelos con q ≤ 2d",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tarea2_cm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}