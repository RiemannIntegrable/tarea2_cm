{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>**Tarea 2: Path Sampling Telesc√≥pico para q-Coloraciones**</center>\n",
    "\n",
    "<center><b>Cadenas de Markov - Maestr√≠a en Actuar√≠a y Finanzas</b></center>\n",
    "<center>Universidad Nacional de Colombia</center>\n",
    "<center>Jos√© Miguel Acu√±a Hern√°ndez</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Importaci√≥n de Librer√≠as**\n",
    "\n",
    "Importamos todas las librer√≠as necesarias para la implementaci√≥n del m√©todo MCMC con path sampling telesc√≥pico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "from numba import njit, prange\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool, TimeoutError as MPTimeoutError\n",
    "import itertools\n",
    "import os\n",
    "import shutil  # Para limpiar directorios temporales\n",
    "import gc  # Para forzar garbage collection\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
    "print(f\"   NumPy version: {np.__version__}\")\n",
    "print(f\"   Numba version: {numba.__version__}\")\n",
    "print(f\"   NetworkX version: {nx.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Configuraci√≥n Global del Experimento**\n",
    "\n",
    "Definimos los par√°metros globales seg√∫n el Theorem 9.1 y las restricciones del problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par√°metros del experimento\n",
    "K_VALUES = list(range(3, 21))  # K = 3, 4, ..., 20\n",
    "Q_VALUES = list(range(2, 16))   # q = 2, 3, ..., 15\n",
    "EPSILON = 0.5                    # Precisi√≥n fija (OPTIMIZADO para rapidez)\n",
    "MAX_SIMULATIONS = 10000           # L√≠mite duro de simulaciones\n",
    "MAX_GIBBS_STEPS = 20000           # L√≠mite duro de pasos Gibbs\n",
    "EXACT_TIMEOUT_SECONDS_Q2 = 2700  # Timeout 45 minutos para q=2 (BASE del telesc√≥pico)\n",
    "EXACT_TIMEOUT_SECONDS = 1200     # Timeout 20 minutos para q>2\n",
    "BATCH_SIZE = 100                 # Tama√±o de batch para procesamiento\n",
    "RESULTS_DIR = 'results_telescopic/'  # Directorio de resultados\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"CONFIGURACI√ìN DEL EXPERIMENTO\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"K values:           {min(K_VALUES)}-{max(K_VALUES)} ({len(K_VALUES)} valores)\")\n",
    "print(f\"q values:           {min(Q_VALUES)}-{max(Q_VALUES)} ({len(Q_VALUES)} valores)\")\n",
    "print(f\"epsilon:            {EPSILON}\")\n",
    "print(f\"Max simulaciones:   {MAX_SIMULATIONS}\")\n",
    "print(f\"Max pasos Gibbs:    {MAX_GIBBS_STEPS}\")\n",
    "print(f\"Timeout exacto q=2: {EXACT_TIMEOUT_SECONDS_Q2}s ({EXACT_TIMEOUT_SECONDS_Q2/60:.0f} min) ‚≠ê\")\n",
    "print(f\"Timeout exacto q>2: {EXACT_TIMEOUT_SECONDS}s ({EXACT_TIMEOUT_SECONDS/60:.0f} min)\")\n",
    "print(f\"Total experimentos: {len(K_VALUES)} √ó {len(Q_VALUES)} = {len(K_VALUES)*len(Q_VALUES)}\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. M√≥dulo 1: C√°lculo de Par√°metros (Theorem 9.1)**\n",
    "\n",
    "Implementamos las f√≥rmulas del Theorem 9.1 para calcular el n√∫mero de simulaciones y pasos de Gibbs requeridos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_required_simulations(K: int, q: int, epsilon: float, d: int = 4) -> int:\n",
    "    \"\"\"\n",
    "    Calcula n√∫mero de simulaciones seg√∫n Theorem 9.1.\n",
    "    Formula: n_sims = ceil(48 * d¬≤ * k¬≥ / Œµ¬≤)\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    K : int\n",
    "        Tama√±o del lattice (K√óK)\n",
    "    q : int\n",
    "        N√∫mero de colores\n",
    "    epsilon : float\n",
    "        Precisi√≥n deseada\n",
    "    d : int\n",
    "        Dimensi√≥n del lattice (default=4 para 2D grid)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    int\n",
    "        N√∫mero de simulaciones requeridas\n",
    "    \"\"\"\n",
    "    k = K * K\n",
    "    n_sims = int(np.ceil(48 * d**2 * k**3 / epsilon**2))\n",
    "    return n_sims\n",
    "\n",
    "\n",
    "def compute_required_gibbs_steps(K: int, q: int, epsilon: float, d: int = 4) -> int:\n",
    "    \"\"\"\n",
    "    Calcula pasos de Gibbs seg√∫n Theorem 9.1.\n",
    "    Formula: gibbs_steps = ceil(k * ((2log(k) + log(1/Œµ) + log(8)) / log(q/(q-1)) + 1))\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    K : int\n",
    "        Tama√±o del lattice (K√óK)\n",
    "    q : int\n",
    "        N√∫mero de colores\n",
    "    epsilon : float\n",
    "        Precisi√≥n deseada\n",
    "    d : int\n",
    "        Dimensi√≥n del lattice (default=4 para 2D grid)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    int\n",
    "        N√∫mero de pasos Gibbs requeridos\n",
    "    \"\"\"\n",
    "    k = K * K\n",
    "    \n",
    "    if q <= 1:\n",
    "        return 1\n",
    "    \n",
    "    log_ratio = np.log(q / (q - 1))\n",
    "    numerator = 2 * np.log(k) + np.log(1/epsilon) + np.log(8)\n",
    "    gibbs_steps = int(np.ceil(k * (numerator / log_ratio + 1)))\n",
    "    \n",
    "    return gibbs_steps\n",
    "\n",
    "\n",
    "def compute_bounded_parameters(K: int, q: int, epsilon: float,\n",
    "                               max_sims: int = 1000, \n",
    "                               max_steps: int = 2000) -> dict:\n",
    "    \"\"\"\n",
    "    Calcula par√°metros con l√≠mites duros aplicados.\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    K : int\n",
    "        Tama√±o del lattice (K√óK)\n",
    "    q : int\n",
    "        N√∫mero de colores\n",
    "    epsilon : float\n",
    "        Precisi√≥n deseada\n",
    "    max_sims : int\n",
    "        L√≠mite m√°ximo de simulaciones\n",
    "    max_steps : int\n",
    "        L√≠mite m√°ximo de pasos Gibbs\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Diccionario con par√°metros requeridos, aplicados y ratios de cumplimiento\n",
    "    \"\"\"\n",
    "    n_sims_req = compute_required_simulations(K, q, epsilon)\n",
    "    gibbs_steps_req = compute_required_gibbs_steps(K, q, epsilon)\n",
    "    \n",
    "    n_sims_actual = min(n_sims_req, max_sims)\n",
    "    gibbs_steps_actual = min(gibbs_steps_req, max_steps)\n",
    "    \n",
    "    is_truncated = (n_sims_actual < n_sims_req) or (gibbs_steps_actual < gibbs_steps_req)\n",
    "    \n",
    "    return {\n",
    "        'n_simulations_required': n_sims_req,\n",
    "        'gibbs_steps_required': gibbs_steps_req,\n",
    "        'n_simulations_actual': n_sims_actual,\n",
    "        'gibbs_steps_actual': gibbs_steps_actual,\n",
    "        'is_truncated': is_truncated,\n",
    "        'compliance_sims': n_sims_actual / n_sims_req if n_sims_req > 0 else 1.0,\n",
    "        'compliance_steps': gibbs_steps_actual / gibbs_steps_req if gibbs_steps_req > 0 else 1.0\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"‚úÖ M√≥dulo 1: Funciones de c√°lculo de par√°metros definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. M√≥dulo 2: Gibbs Sampler Ultra-Optimizado**\n",
    "\n",
    "Implementaci√≥n del Gibbs Sampler con optimizaciones Numba:\n",
    "- Zero allocations\n",
    "- Batch processing con `prange`\n",
    "- Shared adjacency list\n",
    "- `fastmath` y `cache`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def create_adjacency_list(K: int):\n",
    "    \"\"\"\n",
    "    Crea lista de adyacencia para lattice K√óK.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    adj_list : np.ndarray\n",
    "        Matriz (n, 4) con vecinos de cada nodo (-1 si no existe)\n",
    "    degrees : np.ndarray\n",
    "        Array (n,) con grado de cada nodo\n",
    "    \"\"\"\n",
    "    n = K * K\n",
    "    adj_list = np.full((n, 4), -1, dtype=np.int32)\n",
    "    degrees = np.zeros(n, dtype=np.int32)\n",
    "    \n",
    "    for i in range(K):\n",
    "        for j in range(K):\n",
    "            node_idx = i * K + j\n",
    "            deg = 0\n",
    "            \n",
    "            # Vecino arriba\n",
    "            if i > 0:\n",
    "                adj_list[node_idx, deg] = (i - 1) * K + j\n",
    "                deg += 1\n",
    "            # Vecino abajo\n",
    "            if i < K - 1:\n",
    "                adj_list[node_idx, deg] = (i + 1) * K + j\n",
    "                deg += 1\n",
    "            # Vecino izquierda\n",
    "            if j > 0:\n",
    "                adj_list[node_idx, deg] = i * K + (j - 1)\n",
    "                deg += 1\n",
    "            # Vecino derecha\n",
    "            if j < K - 1:\n",
    "                adj_list[node_idx, deg] = i * K + (j + 1)\n",
    "                deg += 1\n",
    "            \n",
    "            degrees[node_idx] = deg\n",
    "    \n",
    "    return adj_list, degrees\n",
    "\n",
    "\n",
    "@njit(fastmath=True, cache=True)\n",
    "def initialize_valid_coloring(n: int, q: int, adj_list: np.ndarray, degrees: np.ndarray):\n",
    "    \"\"\"\n",
    "    Inicializa coloraci√≥n v√°lida usando greedy algorithm.\n",
    "    \"\"\"\n",
    "    coloring = np.zeros(n, dtype=np.int32)\n",
    "    used = np.zeros(q, dtype=np.bool_)\n",
    "    \n",
    "    for node in range(n):\n",
    "        # Marcar colores usados por vecinos\n",
    "        used[:] = False\n",
    "        for i in range(degrees[node]):\n",
    "            neighbor = adj_list[node, i]\n",
    "            if neighbor >= 0 and neighbor < node:\n",
    "                used[coloring[neighbor]] = True\n",
    "        \n",
    "        # Elegir primer color disponible\n",
    "        for c in range(q):\n",
    "            if not used[c]:\n",
    "                coloring[node] = c\n",
    "                break\n",
    "    \n",
    "    return coloring\n",
    "\n",
    "\n",
    "@njit(fastmath=True, cache=True, inline='always')\n",
    "def gibbs_sampler_step_optimized(coloring: np.ndarray, adj_list: np.ndarray,\n",
    "                                  degrees: np.ndarray, q: int, n: int,\n",
    "                                  node_order: np.ndarray, used: np.ndarray,\n",
    "                                  valid_colors: np.ndarray):\n",
    "    \"\"\"\n",
    "    Un paso del Gibbs Sampler SIN ALLOCATIONS.\n",
    "    Recorre todos los nodos en orden aleatorio y re-muestrea su color.\n",
    "    \"\"\"\n",
    "    for idx in range(n):\n",
    "        node = node_order[idx]\n",
    "        \n",
    "        # Marcar colores usados por vecinos\n",
    "        used[:] = False\n",
    "        for i in range(degrees[node]):\n",
    "            neighbor = adj_list[node, i]\n",
    "            if neighbor >= 0:\n",
    "                used[coloring[neighbor]] = True\n",
    "        \n",
    "        # Recolectar colores v√°lidos\n",
    "        n_valid = 0\n",
    "        for c in range(q):\n",
    "            if not used[c]:\n",
    "                valid_colors[n_valid] = c\n",
    "                n_valid += 1\n",
    "        \n",
    "        # Elegir uniformemente entre colores v√°lidos\n",
    "        if n_valid > 0:\n",
    "            chosen_idx = np.random.randint(0, n_valid)\n",
    "            coloring[node] = valid_colors[chosen_idx]\n",
    "\n",
    "\n",
    "@njit(fastmath=True, cache=True)\n",
    "def run_single_gibbs_simulation(K: int, q: int, n_steps: int, seed: int,\n",
    "                                 adj_list: np.ndarray, degrees: np.ndarray):\n",
    "    \"\"\"\n",
    "    Ejecuta UNA simulaci√≥n del Gibbs Sampler.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    coloring : np.ndarray\n",
    "        Coloraci√≥n v√°lida despu√©s de n_steps pasos\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    n = K * K\n",
    "    coloring = initialize_valid_coloring(n, q, adj_list, degrees)\n",
    "    \n",
    "    # Pre-allocate buffers (zero allocations dentro del loop)\n",
    "    node_order = np.arange(n, dtype=np.int32)\n",
    "    used = np.zeros(q, dtype=np.bool_)\n",
    "    valid_colors = np.empty(q, dtype=np.int32)\n",
    "    \n",
    "    for step in range(n_steps):\n",
    "        np.random.shuffle(node_order)\n",
    "        gibbs_sampler_step_optimized(coloring, adj_list, degrees, q, n,\n",
    "                                    node_order, used, valid_colors)\n",
    "    \n",
    "    return coloring\n",
    "\n",
    "\n",
    "@njit(parallel=True, fastmath=True, cache=True)\n",
    "def run_gibbs_batch_parallel(K: int, q: int, n_steps: int, seeds: np.ndarray,\n",
    "                             adj_list: np.ndarray, degrees: np.ndarray):\n",
    "    \"\"\"\n",
    "    Ejecuta BATCH de simulaciones en paralelo usando prange.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    colorings : np.ndarray\n",
    "        Matriz (n_sims, n) con todas las coloraciones generadas\n",
    "    \"\"\"\n",
    "    n_sims = len(seeds)\n",
    "    n = K * K\n",
    "    colorings = np.empty((n_sims, n), dtype=np.int32)\n",
    "    \n",
    "    for i in prange(n_sims):\n",
    "        colorings[i] = run_single_gibbs_simulation(K, q, n_steps, seeds[i],\n",
    "                                                    adj_list, degrees)\n",
    "    \n",
    "    return colorings\n",
    "\n",
    "\n",
    "def run_gibbs_sampling_bounded(K: int, q: int, epsilon: float,\n",
    "                               max_sims: int = 1000, max_steps: int = 2000,\n",
    "                               batch_size: int = 100, verbose: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Ejecuta Gibbs Sampler con l√≠mites duros.\n",
    "    \n",
    "    OPTIMIZACI√ìN: Pre-aloca matriz completa en lugar de append + vstack.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        - colorings: matriz (n_sims, K¬≤) con coloraciones\n",
    "        - params: par√°metros calculados\n",
    "        - elapsed_time: tiempo de ejecuci√≥n\n",
    "    \"\"\"\n",
    "    params = compute_bounded_parameters(K, q, epsilon, max_sims, max_steps)\n",
    "    \n",
    "    n_sims = params['n_simulations_actual']\n",
    "    gibbs_steps = params['gibbs_steps_actual']\n",
    "    \n",
    "    if verbose:\n",
    "        status = \"‚úÖ\" if not params['is_truncated'] else \"‚ö†Ô∏è\"\n",
    "        print(f\"  [{status}] K={K}, q={q}: {n_sims} sims √ó {gibbs_steps} pasos\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Crear lista de adyacencia (compartida por todas las simulaciones)\n",
    "    adj_list, degrees = create_adjacency_list(K)\n",
    "    \n",
    "    # Generar seeds para reproducibilidad\n",
    "    np.random.seed(42 + q)\n",
    "    seeds = np.random.randint(0, 2**31 - 1, size=n_sims)\n",
    "    \n",
    "    # ‚úÖ OPTIMIZACI√ìN: Pre-alocar matriz completa (elimina append + vstack)\n",
    "    n = K * K\n",
    "    colorings = np.empty((n_sims, n), dtype=np.int32)\n",
    "    \n",
    "    # Ejecutar en batches y escribir directamente en posici√≥n correcta\n",
    "    n_batches = int(np.ceil(n_sims / batch_size))\n",
    "    \n",
    "    for batch_idx in range(n_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, n_sims)\n",
    "        batch_seeds = seeds[start_idx:end_idx]\n",
    "        \n",
    "        # Escribir directamente en el slice correspondiente\n",
    "        colorings[start_idx:end_idx] = run_gibbs_batch_parallel(\n",
    "            K, q, gibbs_steps, batch_seeds, adj_list, degrees\n",
    "        )\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    return {\n",
    "        'colorings': colorings,\n",
    "        'params': params,\n",
    "        'elapsed_time': elapsed_time\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"‚úÖ M√≥dulo 2: Gibbs Sampler ultra-optimizado definido [OPTIMIZADO: pre-allocaci√≥n]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. M√≥dulo 3: Conteo Exacto con Timeout**\n",
    "\n",
    "Implementaci√≥n del conteo exacto usando chromatic polynomial con timeout robusto v√≠a multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_exact_colorings_worker(K: int, q: int):\n",
    "    \"\"\"\n",
    "    Worker function para ejecutar en proceso separado.\n",
    "    Enumera exhaustivamente todas las q-coloraciones v√°lidas.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    G = nx.grid_2d_graph(K, K)\n",
    "    nodes = list(G.nodes())\n",
    "    n = len(nodes)\n",
    "    \n",
    "    node_to_idx = {node: i for i, node in enumerate(nodes)}\n",
    "    \n",
    "    # Crear lista de adyacencia\n",
    "    adj = [set() for _ in range(n)]\n",
    "    for u, v in G.edges():\n",
    "        i, j = node_to_idx[u], node_to_idx[v]\n",
    "        adj[i].add(j)\n",
    "        adj[j].add(i)\n",
    "    \n",
    "    # Contar coloraciones v√°lidas\n",
    "    count = 0\n",
    "    for coloring in itertools.product(range(q), repeat=n):\n",
    "        valid = True\n",
    "        for node_idx in range(n):\n",
    "            for neighbor_idx in adj[node_idx]:\n",
    "                if coloring[neighbor_idx] == coloring[node_idx]:\n",
    "                    valid = False\n",
    "                    break\n",
    "            if not valid:\n",
    "                break\n",
    "        if valid:\n",
    "            count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "\n",
    "def compute_exact_colorings_with_timeout(K: int, q: int,\n",
    "                                        timeout_sec: int = 180) -> dict:\n",
    "    \"\"\"\n",
    "    Calcula n√∫mero exacto de q-coloraciones con timeout.\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    K : int\n",
    "        Tama√±o del lattice (K√óK)\n",
    "    q : int\n",
    "        N√∫mero de colores\n",
    "    timeout_sec : int\n",
    "        Timeout en segundos (default 180 = 3 minutos)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        - exact_count: n√∫mero exacto (None si timeout/error)\n",
    "        - status: 'SUCCESS', 'TIMEOUT', o 'ERROR'\n",
    "        - elapsed_time: tiempo transcurrido\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        with Pool(processes=1) as pool:\n",
    "            result_async = pool.apply_async(_compute_exact_colorings_worker, (K, q))\n",
    "            exact_count = result_async.get(timeout=timeout_sec)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        return {\n",
    "            'exact_count': exact_count,\n",
    "            'status': 'SUCCESS',\n",
    "            'elapsed_time': elapsed\n",
    "        }\n",
    "    \n",
    "    except MPTimeoutError:\n",
    "        pool.terminate()\n",
    "        elapsed = time.time() - start_time\n",
    "        return {\n",
    "            'exact_count': None,\n",
    "            'status': 'TIMEOUT',\n",
    "            'elapsed_time': elapsed\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        elapsed = time.time() - start_time\n",
    "        return {\n",
    "            'exact_count': None,\n",
    "            'status': 'ERROR',\n",
    "            'elapsed_time': elapsed,\n",
    "            'error_msg': str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"‚úÖ M√≥dulo 3: Conteo exacto con timeout definido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. M√≥dulo 4: Path Sampling Telesc√≥pico**\n",
    "\n",
    "Implementaci√≥n del m√©todo telesc√≥pico para estimar Z(G,q):\n",
    "\n",
    "$$Z(G,q) = Z(G,2) \\times \\prod_{i=3}^{q} \\frac{Z(G,i)}{Z(G,i-1)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=True, cache=True)\n",
    "def compute_log_available_colors_single(coloring: np.ndarray, adj_list: np.ndarray,\n",
    "                                       degrees: np.ndarray, q: int, K: int,\n",
    "                                       seen_colors: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calcula sum(log(colores_disponibles)) para una coloraci√≥n.\n",
    "    \n",
    "    Esta es la funci√≥n de peso para path sampling:\n",
    "    w(œÉ, q) = ‚àè_v (q - |colores_vecinos(v)|)\n",
    "    \n",
    "    OPTIMIZACI√ìN: Usa array booleano pre-alocado en lugar de set() para velocidad.\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    seen_colors : np.ndarray\n",
    "        Buffer booleano pre-alocado de tama√±o q (reutilizable)\n",
    "    \"\"\"\n",
    "    n = K * K\n",
    "    log_sum = 0.0\n",
    "    \n",
    "    for node in range(n):\n",
    "        # Resetear buffer de colores vistos\n",
    "        seen_colors[:] = False\n",
    "        \n",
    "        # Marcar colores de vecinos como vistos\n",
    "        for i in range(degrees[node]):\n",
    "            neighbor = adj_list[node, i]\n",
    "            if neighbor >= 0:\n",
    "                seen_colors[coloring[neighbor]] = True\n",
    "        \n",
    "        # Contar colores disponibles (no vistos)\n",
    "        available = 0\n",
    "        for c in range(q):\n",
    "            if not seen_colors[c]:\n",
    "                available += 1\n",
    "        \n",
    "        if available > 0:\n",
    "            log_sum += np.log(float(available))\n",
    "    \n",
    "    return log_sum\n",
    "\n",
    "\n",
    "@njit(parallel=True, fastmath=True, cache=True)\n",
    "def compute_log_weights_batch(colorings: np.ndarray, adj_list: np.ndarray,\n",
    "                              degrees: np.ndarray, q: int, K: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calcula log-weights para batch de coloraciones (paralelizado).\n",
    "    \n",
    "    OPTIMIZACI√ìN: Cada thread tiene su propio buffer para evitar race conditions.\n",
    "    \"\"\"\n",
    "    n_samples = colorings.shape[0]\n",
    "    log_weights = np.empty(n_samples, dtype=np.float64)\n",
    "    \n",
    "    for i in prange(n_samples):\n",
    "        # Buffer thread-local para evitar race conditions\n",
    "        seen_colors = np.zeros(q, dtype=np.bool_)\n",
    "        \n",
    "        log_weights[i] = compute_log_available_colors_single(\n",
    "            colorings[i], adj_list, degrees, q, K, seen_colors\n",
    "        )\n",
    "    \n",
    "    return log_weights\n",
    "\n",
    "\n",
    "def estimate_partition_function_single_q(colorings: np.ndarray, K: int, q: int,\n",
    "                                         adj_list: np.ndarray = None,\n",
    "                                         degrees: np.ndarray = None) -> dict:\n",
    "    \"\"\"\n",
    "    Estima Z(G,q) usando path sampling simplificado para UN SOLO q.\n",
    "    \n",
    "    Usa muestras generadas con q colores para estimar Z(G,q).\n",
    "    \n",
    "    OPTIMIZACI√ìN: Recibe adj_list como par√°metro para evitar reconstrucci√≥n.\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    adj_list, degrees : np.ndarray, optional\n",
    "        Si se proporcionan, se reutilizan. Si no, se crean (retrocompatibilidad).\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        - Z_estimate: estimaci√≥n de Z(G,q)\n",
    "        - log_Z: log de la estimaci√≥n\n",
    "        - log_Z_std: desviaci√≥n est√°ndar del log\n",
    "    \"\"\"\n",
    "    # Si no se proporcionan, crearlos (retrocompatibilidad)\n",
    "    if adj_list is None or degrees is None:\n",
    "        adj_list, degrees = create_adjacency_list(K)\n",
    "    \n",
    "    log_weights = compute_log_weights_batch(colorings, adj_list, degrees, q, K)\n",
    "    \n",
    "    mean_log_Z = np.mean(log_weights)\n",
    "    std_log_Z = np.std(log_weights)\n",
    "    \n",
    "    Z_estimate = np.exp(mean_log_Z)\n",
    "    \n",
    "    return {\n",
    "        'Z_estimate': Z_estimate,\n",
    "        'log_Z': mean_log_Z,\n",
    "        'log_Z_std': std_log_Z\n",
    "    }\n",
    "\n",
    "\n",
    "def path_sampling_telescopic(all_colorings_dict: dict, K: int,\n",
    "                             q_max: int = 15, verbose: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Path Sampling TELESC√ìPICO: Z(G,q) = Z(G,2) √ó ‚àè[Z(G,i)/Z(G,i-1)]\n",
    "    \n",
    "    Usa TODAS las muestras generadas (q=2,3,...,q_max) para estimar\n",
    "    el n√∫mero de q-coloraciones de forma telesc√≥pica.\n",
    "    \n",
    "    OPTIMIZACI√ìN: Crea adj_list UNA SOLA VEZ y la reutiliza en todas las llamadas.\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    all_colorings_dict : dict\n",
    "        Diccionario {q: colorings_array} con muestras para cada q\n",
    "    K : int\n",
    "        Tama√±o del lattice\n",
    "    q_max : int\n",
    "        Valor m√°ximo de q\n",
    "    verbose : bool\n",
    "        Mostrar progreso\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Diccionario {q: resultado} con estimaciones para cada q\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n  üî≠ Path Sampling Telesc√≥pico para K={K}\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # ‚úÖ OPTIMIZACI√ìN: Crear lista de adyacencia UNA SOLA VEZ\n",
    "    adj_list, degrees = create_adjacency_list(K)\n",
    "    \n",
    "    # Base: Z(G,2)\n",
    "    est_2 = estimate_partition_function_single_q(\n",
    "        all_colorings_dict[2], K, 2, adj_list, degrees\n",
    "    )\n",
    "    Z_current = est_2['Z_estimate']\n",
    "    log_Z_current = est_2['log_Z']\n",
    "    \n",
    "    results[2] = {\n",
    "        'Z_estimate': Z_current,\n",
    "        'log_Z': log_Z_current,\n",
    "        'log_Z_std': est_2['log_Z_std'],\n",
    "        'method': 'direct'\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"    q=2: Z = {Z_current:.4e}\")\n",
    "    \n",
    "    # Telesc√≥pico: q = 3, 4, ..., q_max\n",
    "    for q in range(3, q_max + 1):\n",
    "        if q not in all_colorings_dict:\n",
    "            continue\n",
    "        \n",
    "        # ‚úÖ Reutilizar adj_list en lugar de recrearla\n",
    "        est_q = estimate_partition_function_single_q(\n",
    "            all_colorings_dict[q], K, q, adj_list, degrees\n",
    "        )\n",
    "        est_q_minus_1 = estimate_partition_function_single_q(\n",
    "            all_colorings_dict[q], K, q-1, adj_list, degrees\n",
    "        )\n",
    "        \n",
    "        ratio = est_q['Z_estimate'] / est_q_minus_1['Z_estimate']\n",
    "        \n",
    "        # Actualizar telesc√≥picamente\n",
    "        Z_current *= ratio\n",
    "        log_Z_current = np.log(Z_current)\n",
    "        \n",
    "        results[q] = {\n",
    "            'Z_estimate': Z_current,\n",
    "            'log_Z': log_Z_current,\n",
    "            'log_Z_std': est_q['log_Z_std'],\n",
    "            'method': 'telescopic',\n",
    "            'ratio': ratio\n",
    "        }\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"    q={q}: Z = {Z_current:.4e} (ratio = {ratio:.4f})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"‚úÖ M√≥dulo 4: Path sampling telesc√≥pico definido [OPTIMIZADO: set()‚Üíarray, reutilizaci√≥n adj_list]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. M√≥dulo 5: Experimento Completo para un K**\n",
    "\n",
    "Orquesta todo el pipeline para un valor de K:\n",
    "1. Generar muestras MCMC para todos los q\n",
    "2. Calcular conteo exacto para cada q\n",
    "3. Aplicar path sampling telesc√≥pico\n",
    "4. Calcular errores y m√©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_for_single_K(K: int, epsilon: float = 0.5,\n",
    "                               max_sims: int = 1000, max_steps: int = 2000,\n",
    "                               exact_timeout: int = 180,\n",
    "                               exact_timeout_q2: int = 600,\n",
    "                               q_values: list = list(range(2, 16)),\n",
    "                               verbose: bool = True,\n",
    "                               timeout_q2_in_previous_K: bool = False,\n",
    "                               results_dir: str = 'results_telescopic/') -> tuple:\n",
    "    \"\"\"\n",
    "    Ejecuta experimento completo para UN K.\n",
    "    \n",
    "    Pipeline:\n",
    "    ---------\n",
    "    1. Para cada q: Generar muestras MCMC + calcular exacto\n",
    "    2. Path sampling telesc√≥pico usando todas las muestras\n",
    "    3. Calcular errores relativos\n",
    "    4. Retornar DataFrame con resultados + flag de timeout en q=2\n",
    "    \n",
    "    OPTIMIZACIONES IMPLEMENTADAS:\n",
    "    - ‚úÖ Guarda coloraciones a disco durante Fase 1 (libera RAM)\n",
    "    - ‚úÖ Carga coloraciones solo cuando se necesitan en Fase 2\n",
    "    - ‚úÖ Limpia archivos temporales al finalizar\n",
    "    - ‚úÖ Libera memoria expl√≠citamente con del + gc.collect()\n",
    "    \n",
    "    IMPORTANTE: \n",
    "    - q=2 usa timeout de 10 minutos (es la base del m√©todo telesc√≥pico)\n",
    "    - q>2 usa timeout de 3 minutos\n",
    "    - Si un q hace timeout, los q siguientes ya no calculan exacto (SKIPPED)\n",
    "    - Si q=2 hace timeout, retorna flag para que NO se calculen exactos en K mayores\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    timeout_q2_in_previous_K : bool\n",
    "        Si True, NO se calcular√°n valores exactos para este K\n",
    "        (porque un K anterior ya tuvo timeout en q=2)\n",
    "    results_dir : str\n",
    "        Directorio donde se guardan resultados y archivos temporales\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple (pd.DataFrame, bool)\n",
    "        - DataFrame con resultados\n",
    "        - bool: True si hubo timeout en q=2 (se√±al para detener exactos en K mayores)\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"EXPERIMENTO COMPLETO: K = {K}\")\n",
    "        print(f\"{'='*80}\")\n",
    "    \n",
    "    # ‚úÖ Crear directorio temporal para coloraciones\n",
    "    temp_colorings_dir = os.path.join(results_dir, f'temp_K{K}_colorings')\n",
    "    os.makedirs(temp_colorings_dir, exist_ok=True)\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    # Flag para detener c√°lculos exactos despu√©s del primer timeout\n",
    "    stop_exact_computation = timeout_q2_in_previous_K\n",
    "    timeout_q2_occurred = False  # Flag espec√≠fico para q=2\n",
    "    \n",
    "    if timeout_q2_in_previous_K and verbose:\n",
    "        print(f\"\\n‚ö†Ô∏è  NOTA: Valores exactos NO se calcular√°n (timeout q=2 en K previo)\")\n",
    "    \n",
    "    # ==========================================\n",
    "    # FASE 1: Generar muestras MCMC y calcular exacto\n",
    "    # ==========================================\n",
    "    if verbose:\n",
    "        print(f\"\\n[FASE 1/2] Generando muestras MCMC y calculando exacto...\")\n",
    "        print(f\"            (Guardando coloraciones a disco para optimizar RAM)\")\n",
    "    \n",
    "    for q in tqdm(q_values, desc=f\"K={K}, q's\", disable=not verbose):\n",
    "        # Generar muestras MCMC (SIEMPRE se genera)\n",
    "        gibbs_result = run_gibbs_sampling_bounded(K, q, epsilon, max_sims, max_steps,\n",
    "                                                  batch_size=100, verbose=False)\n",
    "        \n",
    "        # ‚úÖ OPTIMIZACI√ìN: Guardar coloraciones a disco (formato NPZ comprimido)\n",
    "        colorings_path = os.path.join(temp_colorings_dir, f'colorings_q{q}.npz')\n",
    "        np.savez_compressed(colorings_path, colorings=gibbs_result['colorings'])\n",
    "        \n",
    "        # ‚úÖ OPTIMIZACI√ìN: Liberar memoria inmediatamente\n",
    "        params = gibbs_result['params']\n",
    "        mcmc_time = gibbs_result['elapsed_time']\n",
    "        del gibbs_result  # Liberar diccionario completo\n",
    "        gc.collect()  # Forzar garbage collection\n",
    "        \n",
    "        # Calcular exacto SOLO si no hemos tenido timeout antes\n",
    "        if not stop_exact_computation:\n",
    "            # Usar timeout especial para q=2 (10 min), normal para q>2 (3 min)\n",
    "            timeout_for_this_q = exact_timeout_q2 if q == 2 else exact_timeout\n",
    "            \n",
    "            exact_result = compute_exact_colorings_with_timeout(K, q, timeout_for_this_q)\n",
    "            \n",
    "            # Si q=2 hizo timeout, marcar flag especial\n",
    "            if q == 2 and exact_result['status'] == 'TIMEOUT':\n",
    "                timeout_q2_occurred = True\n",
    "                stop_exact_computation = True\n",
    "                if verbose:\n",
    "                    print(f\"\\n‚ö†Ô∏è  TIMEOUT en q=2 ({timeout_for_this_q}s).\")\n",
    "                    print(f\"    ‚Üí Valores exactos para q>2 en este K: SKIPPED\")\n",
    "                    print(f\"    ‚Üí Valores exactos para K>{K}: NO se calcular√°n ‚≠ê\")\n",
    "            # Si otro q hizo timeout, solo detener para este K\n",
    "            elif exact_result['status'] == 'TIMEOUT':\n",
    "                stop_exact_computation = True\n",
    "                if verbose:\n",
    "                    print(f\"\\n‚ö†Ô∏è  TIMEOUT en q={q} ({timeout_for_this_q}s). Los q siguientes no calcular√°n exacto.\")\n",
    "        else:\n",
    "            # Saltarse c√°lculo exacto (ya hubo timeout antes)\n",
    "            exact_result = {\n",
    "                'exact_count': None,\n",
    "                'status': 'SKIPPED',\n",
    "                'elapsed_time': 0.0\n",
    "            }\n",
    "        \n",
    "        row = {\n",
    "            'q': q,\n",
    "            'n_sims_required': params['n_simulations_required'],\n",
    "            'n_gibbs_steps_required': params['gibbs_steps_required'],\n",
    "            'n_sims_actual': params['n_simulations_actual'],\n",
    "            'n_gibbs_steps_actual': params['gibbs_steps_actual'],\n",
    "            'is_truncated': params['is_truncated'],\n",
    "            'mcmc_time_sec': mcmc_time,\n",
    "            'exact_count': exact_result['exact_count'],\n",
    "            'exact_status': exact_result['status'],\n",
    "            'exact_time_sec': exact_result['elapsed_time']\n",
    "        }\n",
    "        \n",
    "        rows.append(row)\n",
    "        \n",
    "        # ‚úÖ Liberar memoria del resultado exacto\n",
    "        del exact_result\n",
    "        gc.collect()\n",
    "    \n",
    "    # ==========================================\n",
    "    # FASE 2: Path Sampling Telesc√≥pico\n",
    "    # ==========================================\n",
    "    if verbose:\n",
    "        print(f\"\\n[FASE 2/2] Path Sampling Telesc√≥pico...\")\n",
    "        print(f\"            (Cargando coloraciones desde disco)\")\n",
    "    \n",
    "    # ‚úÖ Cargar coloraciones desde disco SOLO cuando se necesitan\n",
    "    all_colorings = {}\n",
    "    for q in q_values:\n",
    "        colorings_path = os.path.join(temp_colorings_dir, f'colorings_q{q}.npz')\n",
    "        data = np.load(colorings_path)\n",
    "        all_colorings[q] = data['colorings']\n",
    "        data.close()  # Cerrar archivo expl√≠citamente\n",
    "    \n",
    "    telescopic_results = path_sampling_telescopic(all_colorings, K,\n",
    "                                                  q_max=max(q_values),\n",
    "                                                  verbose=verbose)\n",
    "    \n",
    "    # ‚úÖ OPTIMIZACI√ìN: Liberar coloraciones inmediatamente despu√©s de usar\n",
    "    del all_colorings\n",
    "    gc.collect()\n",
    "    \n",
    "    # Merge resultados y calcular errores\n",
    "    for row in rows:\n",
    "        q = row['q']\n",
    "        if q in telescopic_results:\n",
    "            row['Z_estimate_mcmc'] = telescopic_results[q]['Z_estimate']\n",
    "            row['log_Z_mcmc'] = telescopic_results[q]['log_Z']\n",
    "            row['log_Z_std'] = telescopic_results[q]['log_Z_std']\n",
    "            \n",
    "            # Calcular error relativo (solo si hay exacto)\n",
    "            if row['exact_status'] == 'SUCCESS':\n",
    "                exact = row['exact_count']\n",
    "                estimate = row['Z_estimate_mcmc']\n",
    "                row['error_rel_pct'] = abs(estimate - exact) / exact * 100\n",
    "            else:\n",
    "                row['error_rel_pct'] = None\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # ‚úÖ OPTIMIZACI√ìN: Limpiar archivos temporales\n",
    "    if os.path.exists(temp_colorings_dir):\n",
    "        shutil.rmtree(temp_colorings_dir)\n",
    "        if verbose:\n",
    "            print(f\"   üßπ Limpieza: Archivos temporales eliminados\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n‚úÖ Experimento K={K} completado\")\n",
    "        print(f\"   Muestras generadas: {len(q_values)} q's\")\n",
    "        print(f\"   Conteo exacto exitoso: {df[df['exact_status']=='SUCCESS'].shape[0]}/{len(q_values)}\")\n",
    "        print(f\"   Conteo exacto timeout:  {df[df['exact_status']=='TIMEOUT'].shape[0]}/{len(q_values)}\")\n",
    "        print(f\"   Conteo exacto saltado:  {df[df['exact_status']=='SKIPPED'].shape[0]}/{len(q_values)}\")\n",
    "        print(f\"   Tiempo total: {df['mcmc_time_sec'].sum() + df['exact_time_sec'].sum():.2f}s\")\n",
    "    \n",
    "    return df, timeout_q2_occurred\n",
    "\n",
    "\n",
    "print(\"‚úÖ M√≥dulo 5: Experimento completo para un K definido [OPTIMIZADO: disco + liberaci√≥n memoria]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. M√≥dulo 6: Loop Principal para Todos los K**\n",
    "\n",
    "Ejecuta experimentos para todos los valores de K y guarda resultados incrementalmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_experiments(K_values: list = list(range(3, 21)),\n",
    "                       epsilon: float = 0.5,\n",
    "                       max_sims: int = 1000, max_steps: int = 2000,\n",
    "                       exact_timeout: int = 180,\n",
    "                       exact_timeout_q2: int = 600,\n",
    "                       q_values: list = list(range(2, 16)),\n",
    "                       results_dir: str = 'results_telescopic/') -> dict:\n",
    "    \"\"\"\n",
    "    Ejecuta TODOS los experimentos para K = 3, 4, ..., 20.\n",
    "    \n",
    "    Guarda resultados incrementalmente (un CSV por K) para tolerancia a fallos.\n",
    "    \n",
    "    OPTIMIZACIONES IMPLEMENTADAS:\n",
    "    - ‚úÖ Coloraciones se guardan/cargan desde disco (optimiza RAM)\n",
    "    - ‚úÖ Liberaci√≥n expl√≠cita de memoria con del + gc.collect()\n",
    "    - ‚úÖ Limpieza autom√°tica de archivos temporales\n",
    "    \n",
    "    IMPORTANTE:\n",
    "    - q=2 usa timeout de 10 minutos (es la base del m√©todo telesc√≥pico)\n",
    "    - q>2 usa timeout de 3 minutos\n",
    "    - Si para un K el c√°lculo exacto de q=2 hace timeout, NO se calcular√°n\n",
    "      valores exactos para K mayores (la complejidad solo crece)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Diccionario {K: DataFrame} con resultados de cada K\n",
    "    \"\"\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(f\"# EXPERIMENTOS TELESC√ìPICOS COMPLETOS\")\n",
    "    print(f\"#\")\n",
    "    print(f\"# K values:        {K_values}\")\n",
    "    print(f\"# q values:        {q_values}\")\n",
    "    print(f\"# epsilon:         {epsilon}\")\n",
    "    print(f\"# Max sims:        {max_sims}\")\n",
    "    print(f\"# Max steps:       {max_steps}\")\n",
    "    print(f\"# Exact timeout q=2: {exact_timeout_q2}s ({exact_timeout_q2/60:.1f} min) ‚≠ê\")\n",
    "    print(f\"# Exact timeout q>2: {exact_timeout}s ({exact_timeout/60:.1f} min)\")\n",
    "    print(f\"#\")\n",
    "    print(f\"# REGLA: Si q=2 hace timeout para un K, NO se calcular√°n exactos\")\n",
    "    print(f\"#        para K mayores (complejidad solo crece)\")\n",
    "    print(f\"#\")\n",
    "    print(f\"# OPTIMIZACIONES: Disco para coloraciones + liberaci√≥n expl√≠cita RAM\")\n",
    "    print(f\"#\")\n",
    "    print(f\"# Total K's:       {len(K_values)}\")\n",
    "    print(f\"{'#'*80}\\n\")\n",
    "    \n",
    "    all_results = {}\n",
    "    timeout_q2_flag = False  # Flag global: si q=2 hizo timeout en alg√∫n K\n",
    "    \n",
    "    for K in K_values:\n",
    "        try:\n",
    "            df_K, timeout_q2_occurred = run_experiment_for_single_K(\n",
    "                K, epsilon, max_sims, max_steps,\n",
    "                exact_timeout, exact_timeout_q2,\n",
    "                q_values, verbose=True,\n",
    "                timeout_q2_in_previous_K=timeout_q2_flag,\n",
    "                results_dir=results_dir  # ‚úÖ Pasar results_dir\n",
    "            )\n",
    "            \n",
    "            all_results[K] = df_K\n",
    "            \n",
    "            # Actualizar flag global si hubo timeout en q=2\n",
    "            if timeout_q2_occurred:\n",
    "                timeout_q2_flag = True\n",
    "                print(f\"\\nüî¥ K={K}: Timeout en q=2 detectado.\")\n",
    "                print(f\"   ‚Üí K mayores ({K+1}+) NO calcular√°n valores exactos\\n\")\n",
    "            \n",
    "            # Guardar CSV incremental\n",
    "            csv_path = os.path.join(results_dir, f'results_K{K}.csv')\n",
    "            df_K.to_csv(csv_path, index=False)\n",
    "            print(f\"   üíæ Guardado: {csv_path}\")\n",
    "            \n",
    "            # ‚úÖ OPTIMIZACI√ìN: Liberar memoria del DataFrame anterior\n",
    "            del df_K\n",
    "            gc.collect()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå ERROR en K={K}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(f\"# TODOS LOS EXPERIMENTOS COMPLETADOS\")\n",
    "    print(f\"# K's exitosos: {len(all_results)}/{len(K_values)}\")\n",
    "    print(f\"{'#'*80}\\n\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "print(\"‚úÖ M√≥dulo 6: Loop principal definido [OPTIMIZADO: gesti√≥n memoria mejorada]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. M√≥dulo 7: An√°lisis y Visualizaciones**Funciones para analizar resultados y generar visualizaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_table(all_results: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Crea tabla resumen consolidada con todos los resultados.\n",
    "    \n",
    "    Incluye columnas te√≥ricas (n_sims_required, n_gibbs_steps_required)\n",
    "    para mostrar los requerimientos del Theorem 9.1.\n",
    "    \"\"\"\n",
    "    all_rows = []\n",
    "    \n",
    "    for K, df_K in all_results.items():\n",
    "        for _, row in df_K.iterrows():\n",
    "            summary_row = {\n",
    "                'K': K,\n",
    "                'q': row['q'],\n",
    "                'n_sims_required': row['n_sims_required'],  # ‚Üê NUEVO\n",
    "                'n_gibbs_steps_required': row['n_gibbs_steps_required'],  # ‚Üê NUEVO\n",
    "                'n_sims_actual': row['n_sims_actual'],\n",
    "                'n_steps_actual': row['n_gibbs_steps_actual'],\n",
    "                'is_truncated': row['is_truncated'],\n",
    "                'Z_estimate': row.get('Z_estimate_mcmc', None),\n",
    "                'exact_count': row['exact_count'],\n",
    "                'exact_status': row['exact_status'],\n",
    "                'error_rel_pct': row.get('error_rel_pct', None)\n",
    "            }\n",
    "            all_rows.append(summary_row)\n",
    "    \n",
    "    return pd.DataFrame(all_rows)\n",
    "\n",
    "\n",
    "def plot_results_summary(all_results: dict, save_path='results_summary_telescopic.png'):\n",
    "    \"\"\"\n",
    "    Genera visualizaciones de resultados.\n",
    "    \n",
    "    Crea 4 gr√°ficos:\n",
    "    1. Heatmap de estimaciones log‚ÇÅ‚ÇÄ(Z(G,q))\n",
    "    2. Heatmap de status de conteo exacto\n",
    "    3. Heatmap de errores relativos\n",
    "    4. Scatter plot MCMC vs Exacto\n",
    "    \"\"\"\n",
    "    df_summary = create_summary_table(all_results)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Heatmap de estimaciones\n",
    "    ax1 = axes[0, 0]\n",
    "    df_with_estimate = df_summary[df_summary['Z_estimate'].notna()].copy()\n",
    "    if len(df_with_estimate) > 0:\n",
    "        pivot_estimates = df_with_estimate.pivot(index='q', columns='K',\n",
    "                                           values='Z_estimate')\n",
    "        pivot_estimates_log = pivot_estimates.applymap(lambda x: np.log10(x) if x > 0 else np.nan)\n",
    "        sns.heatmap(pivot_estimates_log, annot=False, cmap='viridis', ax=ax1)\n",
    "        ax1.set_title('Log‚ÇÅ‚ÇÄ(Z(G,q)) Estimado - Path Sampling Telesc√≥pico')\n",
    "    \n",
    "    # 2. Heatmap de status exacto\n",
    "    ax2 = axes[0, 1]\n",
    "    pivot_exact_status = df_summary.pivot(index='q', columns='K', values='exact_status')\n",
    "    status_map = {'SUCCESS': 1.0, 'TIMEOUT': 0.5, 'SKIPPED': 0.3, 'ERROR': 0.0}\n",
    "    pivot_exact_numeric = pivot_exact_status.applymap(lambda x: status_map.get(x, 0))\n",
    "    sns.heatmap(pivot_exact_numeric, annot=False, cmap='RdYlGn', vmin=0, vmax=1, ax=ax2)\n",
    "    ax2.set_title('Status Conteo Exacto (Verde=Success, Amarillo=Timeout, Naranja=Skipped, Rojo=Error)')\n",
    "    \n",
    "    # 3. Error relativo (donde hay exacto)\n",
    "    ax3 = axes[1, 0]\n",
    "    df_with_exact = df_summary[df_summary['exact_status'] == 'SUCCESS'].copy()\n",
    "    if len(df_with_exact) > 0:\n",
    "        pivot_error = df_with_exact.pivot(index='q', columns='K', values='error_rel_pct')\n",
    "        sns.heatmap(pivot_error, annot=True, fmt='.1f', cmap='YlOrRd', ax=ax3)\n",
    "        ax3.set_title('Error Relativo (%) - MCMC vs Exacto')\n",
    "    \n",
    "    # 4. Scatter: Exacto vs MCMC\n",
    "    ax4 = axes[1, 1]\n",
    "    if len(df_with_exact) > 0:\n",
    "        exact_vals = df_with_exact['exact_count'].values\n",
    "        mcmc_vals = df_with_exact['Z_estimate'].values\n",
    "        \n",
    "        ax4.scatter(np.log10(exact_vals), np.log10(mcmc_vals), alpha=0.6, s=30)\n",
    "        \n",
    "        min_val = min(np.log10(exact_vals).min(), np.log10(mcmc_vals).min())\n",
    "        max_val = max(np.log10(exact_vals).max(), np.log10(mcmc_vals).max())\n",
    "        ax4.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.5)\n",
    "        ax4.set_xlabel('Log‚ÇÅ‚ÇÄ(Exacto)')\n",
    "        ax4.set_ylabel('Log‚ÇÅ‚ÇÄ(MCMC Telesc√≥pico)')\n",
    "        ax4.set_title('Comparaci√≥n MCMC vs Exacto')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úì Visualizaciones guardadas en {save_path}\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ M√≥dulo 7: Funciones de an√°lisis y visualizaci√≥n definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10. An√°lisis de Factibilidad Computacional**\n",
    "\n",
    "Antes de ejecutar los experimentos completos, realizamos un an√°lisis de calibraci√≥n para estimar los tiempos de ejecuci√≥n esperados.\n",
    "\n",
    "### **Experimento de Calibraci√≥n**\n",
    "\n",
    "Ejecutamos un experimento con:\n",
    "- **K = 3** (lattice 3√ó3)\n",
    "- **q = 9** (9 colores)\n",
    "- **Œµ = 0.3** (precisi√≥n moderada)\n",
    "- **Sin l√≠mites** en simulaciones ni pasos Gibbs (usar f√≥rmula completa Theorem 9.1)\n",
    "\n",
    "Con base en el tiempo medido, proyectamos los tiempos para todas las combinaciones (K, q) del estudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento de calibraci√≥n\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENTO DE CALIBRACI√ìN\")\n",
    "print(\"=\"*80)\n",
    "print(\"Par√°metros: K=3, q=9, Œµ=0.3\")\n",
    "print(\"Sin l√≠mites de simulaciones ni pasos Gibbs\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Par√°metros de calibraci√≥n\n",
    "K_CALIB = 3\n",
    "Q_CALIB = 9\n",
    "EPSILON_CALIB = 0.3\n",
    "\n",
    "# Calcular par√°metros requeridos (SIN l√≠mites)\n",
    "n_sims_calib = compute_required_simulations(K_CALIB, Q_CALIB, EPSILON_CALIB)\n",
    "gibbs_steps_calib = compute_required_gibbs_steps(K_CALIB, Q_CALIB, EPSILON_CALIB)\n",
    "\n",
    "print(f\"\\nRequerimientos Theorem 9.1:\")\n",
    "print(f\"  Simulaciones requeridas: {n_sims_calib:,}\")\n",
    "print(f\"  Pasos Gibbs requeridos:  {gibbs_steps_calib:,}\")\n",
    "\n",
    "# Ejecutar experimento de calibraci√≥n (sin l√≠mites)\n",
    "print(f\"\\nEjecutando calibraci√≥n...\")\n",
    "start_calib = time.time()\n",
    "\n",
    "calibration_result = run_gibbs_sampling_bounded(\n",
    "    K=K_CALIB,\n",
    "    q=Q_CALIB,\n",
    "    epsilon=EPSILON_CALIB,\n",
    "    max_sims=n_sims_calib,  # Sin l√≠mites\n",
    "    max_steps=gibbs_steps_calib,  # Sin l√≠mites\n",
    "    batch_size=100,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "tiempo_total_calib = time.time() - start_calib\n",
    "\n",
    "# Calcular tiempo por paso de Gibbs\n",
    "total_gibbs_steps_executed = n_sims_calib * gibbs_steps_calib\n",
    "tiempo_por_paso_gibbs = tiempo_total_calib / total_gibbs_steps_executed\n",
    "\n",
    "print(f\"\\n‚úÖ Calibraci√≥n completada\")\n",
    "print(f\"   Tiempo total:           {tiempo_total_calib:.2f}s\")\n",
    "print(f\"   Pasos Gibbs totales:    {total_gibbs_steps_executed:,}\")\n",
    "print(f\"   Tiempo por paso Gibbs:  {tiempo_por_paso_gibbs*1e6:.4f} Œºs/paso\")\n",
    "print(f\"   ({tiempo_por_paso_gibbs:.6e} s/paso)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Liberar memoria\n",
    "del calibration_result\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proyecci√≥n de tiempos para todas las combinaciones (K, q)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROYECCI√ìN DE TIEMPOS DE EJECUCI√ìN\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Usando tiempo por paso calibrado: {tiempo_por_paso_gibbs:.6e} s/paso\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear DataFrame con proyecciones\n",
    "projection_rows = []\n",
    "\n",
    "for K in K_VALUES:\n",
    "    for q in Q_VALUES:\n",
    "        # Calcular par√°metros seg√∫n Theorem 9.1 con Œµ=0.3\n",
    "        n_sims = compute_required_simulations(K, q, EPSILON_CALIB)\n",
    "        gibbs_steps = compute_required_gibbs_steps(K, q, EPSILON_CALIB)\n",
    "        \n",
    "        # Proyectar tiempo total\n",
    "        total_steps = n_sims * gibbs_steps\n",
    "        tiempo_estimado_seg = total_steps * tiempo_por_paso_gibbs\n",
    "        \n",
    "        projection_rows.append({\n",
    "            'K': K,\n",
    "            'q': q,\n",
    "            'n_sims': n_sims,\n",
    "            'gibbs_steps': gibbs_steps,\n",
    "            'total_steps': total_steps,\n",
    "            'tiempo_seg': tiempo_estimado_seg,\n",
    "            'tiempo_min': tiempo_estimado_seg / 60,\n",
    "            'tiempo_horas': tiempo_estimado_seg / 3600\n",
    "        })\n",
    "\n",
    "df_projection = pd.DataFrame(projection_rows)\n",
    "\n",
    "# Guardar CSV\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "projection_csv_path = os.path.join(RESULTS_DIR, 'feasibility_analysis.csv')\n",
    "df_projection.to_csv(projection_csv_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Proyecciones calculadas para {len(df_projection)} combinaciones (K,q)\")\n",
    "print(f\"   Guardado: {projection_csv_path}\")\n",
    "\n",
    "# Mostrar estad√≠sticas de tiempos proyectados\n",
    "print(f\"\\nEstad√≠sticas de tiempos proyectados:\")\n",
    "print(f\"  M√≠nimo:  {df_projection['tiempo_seg'].min():.2f}s ({df_projection['tiempo_seg'].min()/60:.2f} min)\")\n",
    "print(f\"  M√°ximo:  {df_projection['tiempo_seg'].max():.2f}s ({df_projection['tiempo_horas'].max():.2f} horas)\")\n",
    "print(f\"  Media:   {df_projection['tiempo_seg'].mean():.2f}s ({df_projection['tiempo_min'].mean():.2f} min)\")\n",
    "print(f\"  Mediana: {df_projection['tiempo_seg'].median():.2f}s ({df_projection['tiempo_min'].median():.2f} min)\")\n",
    "\n",
    "# Tiempo total proyectado\n",
    "tiempo_total_proyectado = df_projection['tiempo_seg'].sum()\n",
    "print(f\"\\nTiempo total proyectado (todos los experimentos):\")\n",
    "print(f\"  {tiempo_total_proyectado:.2f}s\")\n",
    "print(f\"  {tiempo_total_proyectado/60:.2f} minutos\")\n",
    "print(f\"  {tiempo_total_proyectado/3600:.2f} horas\")\n",
    "print(f\"  {tiempo_total_proyectado/86400:.2f} d√≠as\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Mostrar preview del DataFrame\n",
    "print(f\"\\nPreview de proyecciones (primeras 10 filas):\")\n",
    "display(df_projection.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear 18 gr√°ficas individuales (una por cada K)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERANDO GR√ÅFICAS DE FACTIBILIDAD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear figura con 18 subplots (grid 3x6)\n",
    "fig, axes = plt.subplots(3, 6, figsize=(24, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Funci√≥n auxiliar para formatear tiempos\n",
    "def format_time(seconds):\n",
    "    \"\"\"Retorna tiempo en la unidad m√°s apropiada\"\"\"\n",
    "    if seconds < 60:\n",
    "        return seconds, 'segundos'\n",
    "    elif seconds < 3600:\n",
    "        return seconds / 60, 'minutos'\n",
    "    elif seconds < 86400:\n",
    "        return seconds / 3600, 'horas'\n",
    "    else:\n",
    "        return seconds / 86400, 'd√≠as'\n",
    "\n",
    "# Para cada K, crear una gr√°fica\n",
    "for idx, K in enumerate(K_VALUES):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Filtrar datos para este K\n",
    "    df_K = df_projection[df_projection['K'] == K]\n",
    "    \n",
    "    # Determinar escala autom√°tica seg√∫n magnitud\n",
    "    max_time_seg = df_K['tiempo_seg'].max()\n",
    "    time_values, time_unit = format_time(max_time_seg)\n",
    "    \n",
    "    # Convertir todos los tiempos a la unidad seleccionada\n",
    "    if time_unit == 'segundos':\n",
    "        y_values = df_K['tiempo_seg'].values\n",
    "    elif time_unit == 'minutos':\n",
    "        y_values = df_K['tiempo_min'].values\n",
    "    elif time_unit == 'horas':\n",
    "        y_values = df_K['tiempo_horas'].values\n",
    "    else:  # d√≠as\n",
    "        y_values = df_K['tiempo_seg'].values / 86400\n",
    "    \n",
    "    # Graficar\n",
    "    ax.plot(df_K['q'].values, y_values, marker='o', linewidth=2, markersize=6, color='steelblue')\n",
    "    ax.fill_between(df_K['q'].values, y_values, alpha=0.3, color='steelblue')\n",
    "    \n",
    "    # Etiquetas y t√≠tulo\n",
    "    ax.set_xlabel('q (n√∫mero de colores)', fontsize=9)\n",
    "    ax.set_ylabel(f'Tiempo ({time_unit})', fontsize=9)\n",
    "    ax.set_title(f'K = {K} (Lattice {K}√ó{K})', fontsize=10, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax.set_xticks(Q_VALUES)\n",
    "    \n",
    "    # Formato de los valores del eje Y\n",
    "    ax.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n",
    "plt.suptitle('Tiempos de Ejecuci√≥n Proyectados por K (Œµ=0.3)', \n",
    "             fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar figura\n",
    "plots_path = os.path.join(RESULTS_DIR, 'feasibility_plots.png')\n",
    "plt.savefig(plots_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Gr√°ficas generadas y guardadas\")\n",
    "print(f\"   Archivo: {plots_path}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fin del An√°lisis de Factibilidad**\n",
    "\n",
    "Con base en las proyecciones anteriores, procedemos a ejecutar los experimentos principales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **11. EJECUCI√ìN DE EXPERIMENTOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESCOMENTAR PARA EJECUTAR EXPERIMENTOS COMPLETOS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENTOS COMPLETOS: K=3..20\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_results = run_all_experiments(\n",
    "    K_values=K_VALUES,\n",
    "    epsilon=EPSILON,\n",
    "    max_sims=MAX_SIMULATIONS,\n",
    "    max_steps=MAX_GIBBS_STEPS,\n",
    "    exact_timeout=EXACT_TIMEOUT_SECONDS,\n",
    "    exact_timeout_q2=EXACT_TIMEOUT_SECONDS_Q2,\n",
    "    q_values=Q_VALUES,\n",
    "    results_dir=RESULTS_DIR\n",
    ")\n",
    "\n",
    "# Crear tabla resumen\n",
    "df_summary = create_summary_table(all_results)\n",
    "summary_path = os.path.join(RESULTS_DIR, 'summary_all_results.csv')\n",
    "df_summary.to_csv(summary_path, index=False)\n",
    "print(f\"\\nüíæ Tabla resumen guardada: {summary_path}\")\n",
    "\n",
    "# Generar visualizaciones\n",
    "plot_path = os.path.join(RESULTS_DIR, 'results_summary_telescopic.png')\n",
    "plot_results_summary(all_results, save_path=plot_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENTOS COMPLETADOS CON √âXITO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Resultados guardados en: {RESULTS_DIR}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **12. AN√ÅLISIS DE RESULTADOS**\n",
    "\n",
    "### **Cargar resultados existentes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar todos los CSVs generados\n",
    "import glob\n",
    "\n",
    "csv_files = glob.glob(os.path.join(RESULTS_DIR, 'results_K*.csv'))\n",
    "print(f\"\\nüìÅ Archivos encontrados: {len(csv_files)}\")\n",
    "\n",
    "if len(csv_files) > 0:\n",
    "    loaded_results = {}\n",
    "    for csv_file in sorted(csv_files):\n",
    "        K = int(csv_file.split('_K')[1].split('.csv')[0])\n",
    "        loaded_results[K] = pd.read_csv(csv_file)\n",
    "        print(f\"   Cargado: K={K} ({loaded_results[K].shape[0]} filas)\")\n",
    "    \n",
    "    df_all = create_summary_table(loaded_results)\n",
    "    print(f\"\\nüìä DataFrame consolidado: {df_all.shape}\")\n",
    "    display(df_all.head(20))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No se encontraron resultados. Ejecuta primero los experimentos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Estad√≠sticas descriptivas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(csv_files) > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ESTAD√çSTICAS DESCRIPTIVAS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Conteos por status\n",
    "    print(\"\\n1. Status de conteo exacto:\")\n",
    "    status_counts = df_all['exact_status'].value_counts()\n",
    "    print(status_counts)\n",
    "    print(f\"\\n   Desglose:\")\n",
    "    for status in ['SUCCESS', 'TIMEOUT', 'SKIPPED', 'ERROR']:\n",
    "        count = status_counts.get(status, 0)\n",
    "        pct = (count / len(df_all) * 100) if len(df_all) > 0 else 0\n",
    "        print(f\"   {status:8s}: {count:3d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Errores relativos (donde hay exacto)\n",
    "    df_with_exact = df_all[df_all['exact_status'] == 'SUCCESS'].copy()\n",
    "    if len(df_with_exact) > 0:\n",
    "        print(\"\\n2. Errores relativos (%) [Solo casos con exacto]:\")\n",
    "        print(f\"   Media:    {df_with_exact['error_rel_pct'].mean():.2f}%\")\n",
    "        print(f\"   Mediana:  {df_with_exact['error_rel_pct'].median():.2f}%\")\n",
    "        print(f\"   Std:      {df_with_exact['error_rel_pct'].std():.2f}%\")\n",
    "        print(f\"   Min:      {df_with_exact['error_rel_pct'].min():.2f}%\")\n",
    "        print(f\"   Max:      {df_with_exact['error_rel_pct'].max():.2f}%\")\n",
    "    \n",
    "    # Truncamiento\n",
    "    print(\"\\n3. Casos truncados (l√≠mites aplicados):\")\n",
    "    n_truncated = df_all['is_truncated'].sum()\n",
    "    print(f\"   Truncados: {n_truncated}/{len(df_all)} ({n_truncated/len(df_all)*100:.1f}%)\")\n",
    "    \n",
    "    # Efecto de q > 2d\n",
    "    df_all['satisfies_theorem'] = df_all['q'] > 8  # 2d = 8\n",
    "    print(\"\\n4. Comparaci√≥n q ‚â§ 8 vs q > 8 (restricci√≥n Theorem 9.1):\")\n",
    "    for satisfies, group in df_all[df_all['exact_status']=='SUCCESS'].groupby('satisfies_theorem'):\n",
    "        label = \"q > 8\" if satisfies else \"q ‚â§ 8\"\n",
    "        print(f\"   {label}: Error medio = {group['error_rel_pct'].mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualizaciones adicionales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(csv_files) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # 1. Distribuci√≥n de errores\n",
    "    ax1 = axes[0]\n",
    "    if len(df_with_exact) > 0:\n",
    "        df_with_exact['error_rel_pct'].hist(bins=30, ax=ax1, edgecolor='black')\n",
    "        ax1.set_xlabel('Error Relativo (%)')\n",
    "        ax1.set_ylabel('Frecuencia')\n",
    "        ax1.set_title('Distribuci√≥n de Errores Relativos')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Error vs q\n",
    "    ax2 = axes[1]\n",
    "    if len(df_with_exact) > 0:\n",
    "        for K in df_with_exact['K'].unique():\n",
    "            df_K = df_with_exact[df_with_exact['K'] == K]\n",
    "            ax2.plot(df_K['q'], df_K['error_rel_pct'], marker='o', alpha=0.6, label=f'K={K}')\n",
    "        ax2.axvline(x=8, color='red', linestyle='--', alpha=0.5, label='q=2d=8')\n",
    "        ax2.set_xlabel('q (n√∫mero de colores)')\n",
    "        ax2.set_ylabel('Error Relativo (%)')\n",
    "        ax2.set_title('Error vs q para diferentes K')\n",
    "        ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tarea2_cm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
